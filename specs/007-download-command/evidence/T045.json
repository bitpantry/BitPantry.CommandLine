{
  "taskId": "T045",
  "testCase": "",
  "green": {
    "timestamp": "2026-01-11T20:56:04.0189025-06:00",
    "testCommand": "",
    "exitCode": 0,
    "output": ""
  },
  "diff": {
    "timestamp": "2026-01-11T20:56:04.0189025-06:00",
    "files": [
      ".claude/commands/speckit.analyze.md",
      ".claude/commands/speckit.implement.md",
      ".claude/commands/speckit.tasks.md",
      ".specify/templates/tasks-template.md",
      "BitPantry.CommandLine.Remote.SignalR.Client/Commands/Server/DownloadCommand.cs",
      "BitPantry.CommandLine.Remote.SignalR.Client/Commands/Server/UploadCommand.cs",
      "BitPantry.CommandLine.Remote.SignalR.Client/GlobPatternHelper.cs",
      "BitPantry.CommandLine.Tests.Remote.SignalR/ClientTests/DownloadCommandTests.cs",
      "BitPantry.CommandLine.Tests.Remote.SignalR/ClientTests/FileTransferServiceAuthTests.cs",
      "BitPantry.CommandLine.Tests.Remote.SignalR/ClientTests/FileTransferServiceDownloadTests.cs",
      "BitPantry.CommandLine.Tests.Remote.SignalR/ClientTests/GlobPatternHelperTests.cs",
      "BitPantry.CommandLine.Tests.Remote.SignalR/ClientTests/UploadCommandTests.cs",
      "CLAUDE.md"
    ],
    "patch": "diff --git a/.claude/commands/speckit.analyze.md b/.claude/commands/speckit.analyze.md\nindex 674d24a..da26c0a 100644\n--- a/.claude/commands/speckit.analyze.md\n+++ b/.claude/commands/speckit.analyze.md\n@@ -135,14 +135,59 @@ Focus on high-signal findings. Limit to 50 findings total; aggregate remainder i\n - Task ordering contradictions (e.g., integration tasks before foundational setup tasks without dependency note)\n - Conflicting requirements (e.g., one requires Next.js while other specifies Vue)\n \n+#### H. Workflow Integrity (Micro-TDD Validation)\n+\n+Run `.specify/scripts/powershell/analyze-workflow.ps1 -Json` to validate workflow state:\n+\n+**Task Format Compliance:**\n+- Every task must match format: `- [ ] T### [depends:T###,T###] @test-case:XX-### Description`\n+- Task IDs must be sequential (T001, T002, T003...)\n+- Dependencies must reference valid task IDs\n+- Each task (except SETUP-###) must have exactly ONE `@test-case:` reference\n+- The old `[P]` and `[US#]` markers must NOT appear (obsolete)\n+\n+**Test Case Coverage:**\n+- Every test case ID in test-cases.md must have exactly ONE corresponding task\n+- No test case should be referenced by multiple tasks\n+- No task should reference multiple test cases (except SETUP-### tasks)\n+\n+**Dependency Acyclicity:**\n+- Dependencies must form a valid Directed Acyclic Graph (DAG)\n+- No circular dependencies (T001 ΓåÆ T002 ΓåÆ T001)\n+- Report cycle paths if detected\n+\n+**Batch Integrity (if batches exist):**\n+- Batch files in `batches/` directory must contain valid task references\n+- Batch task order must respect dependency constraints\n+- Each batch should have 10-15 tasks\n+- Tasks should not appear in multiple batches\n+\n+**State Consistency (if batch-state.json exists):**\n+- Active batch must reference existing batch file\n+- Current task must be in active batch\n+- Task phases must be valid (started ΓåÆ red ΓåÆ green ΓåÆ verified)\n+- No task in later phase without evidence for earlier phases\n+\n+**Evidence Completeness (if evidence/ directory exists):**\n+- Each completed task must have evidence file at `evidence/T###.json`\n+- Evidence must contain: phase, taskId, red section, green section\n+- Red section must show test failure output\n+- Green section must show test passing output\n+- Diff section should show implementation changes\n+\n+**Sequence Integrity:**\n+- Tasks marked complete must have been verified\n+- Tasks in \"green\" phase must have evidence of red phase first\n+- No task should be marked complete without both red and green evidence\n+\n ### 5. Severity Assignment\n \n Use this heuristic to prioritize findings:\n \n-- **CRITICAL**: Violates constitution MUST, missing core spec artifact, requirement with zero coverage that blocks baseline functionality, or test-cases.md missing when TDD mandated\n-- **HIGH**: Duplicate or conflicting requirement, ambiguous security/performance attribute, untestable acceptance criterion, test cases with no implementing tasks, user stories or functional requirements with no test cases\n-- **MEDIUM**: Terminology drift, missing non-functional task coverage, underspecified edge case, vague test case assertions, edge cases or components without test cases\n-- **LOW**: Style/wording improvements, minor redundancy not affecting execution order\n+- **CRITICAL**: Violates constitution MUST, missing core spec artifact, requirement with zero coverage that blocks baseline functionality, test-cases.md missing when TDD mandated, circular dependencies in tasks, task format violations, missing evidence for completed tasks\n+- **HIGH**: Duplicate or conflicting requirement, ambiguous security/performance attribute, untestable acceptance criterion, test cases with no implementing tasks, user stories or functional requirements with no test cases, batch-state.json inconsistencies, multiple tasks referencing same test case\n+- **MEDIUM**: Terminology drift, missing non-functional task coverage, underspecified edge case, vague test case assertions, edge cases or components without test cases, batch sizing issues (too few or too many tasks)\n+- **LOW**: Style/wording improvements, minor redundancy not affecting execution order, evidence format warnings\n \n ### 6. Produce Compact Analysis Report\n \n@@ -193,13 +238,30 @@ Output a Markdown report (no file writes) with the following structure:\n - Duplication Count\n - Critical Issues Count\n \n+**Workflow Integrity (if batches exist):**\n+\n+| Check | Status | Details |\n+|-------|--------|---------|\n+| Task Format Compliance | Γ£à/Γ¥î | X of Y tasks valid |\n+| Dependency DAG | Γ£à/Γ¥î | Acyclic / Cycles detected |\n+| Batch Sizing | Γ£à/Γ¥î | Batches in 10-15 range |\n+| State Consistency | Γ£à/Γ¥î | batch-state.json valid |\n+| Evidence Completeness | Γ£à/Γ¥î | X of Y completed tasks have evidence |\n+| Sequence Integrity | Γ£à/Γ¥î | All redΓåÆgreen sequences valid |\n+\n ### 7. Provide Next Actions\n \n At end of report, output a concise Next Actions block:\n \n-- If CRITICAL issues exist: Recommend resolving before `/speckit.implement`\n+- If CRITICAL issues exist: Recommend resolving before `/speckit.batch`\n - If only LOW/MEDIUM: User may proceed, but provide improvement suggestions\n-- Provide explicit command suggestions: e.g., \"Run /speckit.specify with refinement\", \"Run /speckit.plan to adjust architecture\", \"Manually edit tasks.md to add coverage for 'performance-metrics'\"\n+- Provide explicit command suggestions:\n+  - For spec issues: \"Run /speckit.specify with refinement\"\n+  - For plan issues: \"Run /speckit.plan to adjust architecture\"\n+  - For task coverage: \"Manually edit tasks.md to add coverage for 'performance-metrics'\"\n+  - For task format issues: \"Run /speckit.tasks to regenerate with correct format\"\n+  - For workflow state issues: \"Run /speckit.recover to diagnose and fix state\"\n+  - For batch issues: \"Run /speckit.batch to create or advance batches\"\n \n ### 8. Interactive Remediation Workflow\n \ndiff --git a/.claude/commands/speckit.implement.md b/.claude/commands/speckit.implement.md\ndeleted file mode 100644\nindex 6b5e869..0000000\n--- a/.claude/commands/speckit.implement.md\n+++ /dev/null\n@@ -1,292 +0,0 @@\n----\n-description: Execute the implementation plan by processing and executing all tasks defined in tasks.md\n----\n-\n-## User Input\n-\n-```text\n-$ARGUMENTS\n-```\n-\n-You **MUST** consider the user input before proceeding (if not empty).\n-\n-## Outline\n-\n-1. Run `.specify/scripts/powershell/check-prerequisites.ps1 -Json -RequireTasks -IncludeTasks` from repo root and parse FEATURE_DIR and AVAILABLE_DOCS list. All paths must be absolute. For single quotes in args like \"I'm Groot\", use escape syntax: e.g 'I'\\''m Groot' (or double-quote if possible: \"I'm Groot\").\n-\n-2. **Check checklists status** (if FEATURE_DIR/checklists/ exists):\n-   - Scan all checklist files in the checklists/ directory\n-   - For each checklist, count:\n-     - Total items: All lines matching `- [ ]` or `- [X]` or `- [x]`\n-     - Completed items: Lines matching `- [X]` or `- [x]`\n-     - Incomplete items: Lines matching `- [ ]`\n-   - Create a status table:\n-\n-     ```text\n-     | Checklist | Total | Completed | Incomplete | Status |\n-     |-----------|-------|-----------|------------|--------|\n-     | ux.md     | 12    | 12        | 0          | Γ£ô PASS |\n-     | test.md   | 8     | 5         | 3          | Γ£ù FAIL |\n-     | security.md | 6   | 6         | 0          | Γ£ô PASS |\n-     ```\n-\n-   - Calculate overall status:\n-     - **PASS**: All checklists have 0 incomplete items\n-     - **FAIL**: One or more checklists have incomplete items\n-\n-   - **If any checklist is incomplete**:\n-     - Display the table with incomplete item counts\n-     - **STOP** and ask: \"Some checklists are incomplete. Do you want to proceed with implementation anyway? (yes/no)\"\n-     - Wait for user response before continuing\n-     - If user says \"no\" or \"wait\" or \"stop\", halt execution\n-     - If user says \"yes\" or \"proceed\" or \"continue\", proceed to step 3\n-\n-   - **If all checklists are complete**:\n-     - Display the table showing all checklists passed\n-     - Automatically proceed to step 3\n-\n----\n-\n-### ΓÜá∩╕Å Decision Point Protocol\n-\n-**DO NOT assume to fill gaps.** When you encounter ambiguity that requires assumption to proceed:\n-\n-1. **STOP** implementation immediately\n-2. **PRESENT** the decision point:\n-   - What specific gap or ambiguity was encountered\n-   - Where it was found (task, spec, plan, or missing entirely)\n-   - Available options with trade-offs for each\n-   - **TOP RECOMMENDATION**: Your single best recommendation (marked clearly)\n-3. **WAIT** for user input before proceeding\n-\n-**Applies to**: Technical ambiguities (e.g., unspecified validation rules, unclear architecture choices) AND process decisions (e.g., how to handle a failed task, unexpected state).\n-\n-**Threshold**: Stop only when the decision could meaningfully impact implementation or when filling the gap requires non-trivial assumption. Trivial decisions (e.g., variable naming style consistent with codebase) can proceed.\n-\n----\n-\n-### ≡ƒÜÇ Continuous Execution Directive\n-\n-**Execute all tasks without pausing for confirmation.** Do NOT:\n-- Stop to give progress updates and ask \"should I continue?\"\n-- Pause between phases to ask for permission to proceed\n-- Request confirmation before starting the next task\n-- Summarize completed work mid-execution and wait for acknowledgment\n-\n-**Keep executing** until one of these occurs:\n-1. **Decision Point Protocol triggered** - ambiguity requiring user input\n-2. **Test Integrity Protocol triggered** - test modification requiring approval\n-3. **All tasks completed** - report final summary\n-4. **Blocking error** - cannot proceed without resolution\n-\n-**Task completion ritual**: After completing each task:\n-1. Update tasks.md: change `- [ ]` to `- [X]` for that task\n-2. Immediately proceed to the next task\n-\n-**Batch your work**: Complete as many tasks as possible in each response. Use parallel tool calls where appropriate. Minimize round-trips.\n-\n----\n-\n-### ≡ƒº¬ Test Integrity Protocol\n-\n-**Tests are specifications, not just verification.** A test encodes business intent and expected behavior. When a test fails:\n-\n-**Default Assumption**: The **code is wrong**, not the test.\n-\n-**Test cases as source of truth**: Each test should implement one or more test cases from test-cases.md. The \"When X, Then Y\" definition in test-cases.md is the authoritative specification for what the test should verify.\n-\n-**Before modifying ANY test assertion or constraint**:\n-\n-1. **ARTICULATE** the test's original intent:\n-   - What test case ID(s) does this test implement? (e.g., UX-001, CV-003)\n-   - What is the \"When X, Then Y\" from test-cases.md?\n-   - Why were these specific assertions chosen?\n-\n-2. **DIAGNOSE** the failure:\n-   - Is the code not implementing the intended behavior? ΓåÆ **Fix the code**\n-   - Is the test's intent outdated due to legitimate spec change? ΓåÆ **Confirm with user**\n-   - Is the test technically flawed (wrong setup, race condition)? ΓåÆ **Fix test mechanics, preserve intent**\n-\n-3. **NEVER do the following without explicit user approval**:\n-   - Weaken assertions (e.g., `Should().ContainExactly(3)` ΓåÆ `Should().HaveCountGreaterThan(0)`)\n-   - Remove assertions that are failing\n-   - Change expected values to match current (buggy) behavior\n-   - Generalize specific checks (e.g., `item.Name == \"Settings\"` ΓåÆ `item.Name != null`)\n-\n-**If you believe a test's intent is wrong**, trigger the **Decision Point Protocol**:\n-- Present the test's apparent intent\n-- Explain why you believe the intent (not just the code) is incorrect\n-- **TOP RECOMMENDATION**: Your suggested resolution\n-- **WAIT** for user confirmation before modifying test expectations\n-\n-**Legitimate test modifications** (no approval needed):\n-- Fixing test setup/teardown mechanics\n-- Updating imports or references after refactoring\n-- Adjusting timing/async handling while preserving assertions\n-- Adding MORE specific assertions (strengthening, not weakening)\n-\n----\n-\n-### ≡ƒÄ» Test Writing Discipline (TDD)\n-\n-When writing tests FIRST (before implementation), apply structured thinking:\n-\n-**1. Articulate the Behavioral Hypothesis**\n-\n-Before writing assertions, state what you expect:\n-> \"When [condition], the system should [expected behavior] because [rationale]\"\n-\n-This transforms the test case's \"When X, Then Y\" into a testable prediction. If you can't articulate the hypothesis, the requirement may be underspecified.\n-\n-**2. Check for Existing Patterns**\n-\n-Before creating a new test:\n-- Search for similar tests in the same test file/class\n-- Look for established patterns (setup helpers, assertion styles, mock configurations)\n-- Reuse existing test infrastructure rather than inventing new approaches\n-- If no patterns exist, you're establishing oneΓÇöbe intentional about it\n-\n-**3. Consider Platform-Specific Behavior**\n-\n-For tests involving:\n-- **Path manipulation**: `Path.IsPathRooted(\"/\")` returns `true` on Windows, `false` on Unix\n-- **Line endings**: `\\r\\n` vs `\\n`\n-- **File system case sensitivity**: Windows is case-insensitive, Linux is case-sensitive\n-- **Environment variables**: Different conventions per OS\n-\n-Either:\n-- Mock the platform-specific API (preferred for unit tests)\n-- Use abstractions like `System.IO.Abstractions`\n-- Document platform assumptions in test comments\n-\n----\n-\n-### Γ£à Test Quality Requirements\n-\n-Tests MUST verify the actual behavior specified in test-cases.md, not implementation artifacts.\n-\n-**The \"Then\" Must Be Tested Directly**:\n-- Read the test case's \"Then\" column from test-cases.md\n-- Your test assertion MUST verify that specific outcome\n-- If \"Then\" says \"only 4 uploads active simultaneously\", the test must observe actual concurrency\n-\n-**Invalid Test Patterns** (NEVER do these):\n-- Γ¥î Testing constants: `MaxConcurrency.Should().Be(4)` - proves nothing about behavior\n-- Γ¥î Testing input strings: `pattern.Contains(\"*\").Should().BeTrue()` - tests the input, not the processing\n-- Γ¥î Testing types exist: `typeof(UploadCommand).Should().NotBeNull()` - compiler already guarantees this\n-- Γ¥î Testing attributes: `property.GetCustomAttributes().Should().Contain(...)` - tests metadata, not behavior\n-- Γ¥î Tautologies: `result.Should().Be(result)` - always passes, proves nothing\n-\n-**Valid Test Patterns**:\n-- Γ£à Execute code and verify observable outcome\n-- Γ£à Mock dependencies and verify interactions (method calls, arguments passed)\n-- Γ£à Create real test fixtures (temp files, test data) and verify state changes\n-- Γ£à Capture side effects (console output, file creation, HTTP calls)\n-\n-**When Behavior Is Hard to Test**:\n-If the \"Then\" from test-cases.md is difficult to verify:\n-1. **First choice**: Refactor code to be more testable (inject dependencies, return values instead of void)\n-2. **Second choice**: Use integration tests with real dependencies\n-3. **NEVER**: Write a fake test that tests something other than the specified behavior\n-\n-**Verification Question**: Before marking a test task complete, ask:\n-> \"If someone broke the behavior described in the 'Then' column, would this test fail?\"\n-> If the answer is \"no\", the test is invalid and must be rewritten.\n-\n----\n-\n-3. Load and analyze the implementation context:\n-   - **REQUIRED**: Read tasks.md for the complete task list and execution plan\n-   - **REQUIRED**: Read plan.md for tech stack, architecture, and file structure\n-   - **REQUIRED**: Read test-cases.md for test case definitions (When X, Then Y)\n-   - **REQUIRED**: Read .specify/memory/constitution.md for project principles and testing infrastructure\n-   - **IF EXISTS**: Read data-model.md for entities and relationships\n-   - **IF EXISTS**: Read contracts/ for API specifications and test requirements\n-   - **IF EXISTS**: Read research.md for technical decisions and constraints\n-   - **IF EXISTS**: Read quickstart.md for integration scenarios\n-\n-4. **Project Setup Verification**:\n-   - **REQUIRED**: Create/verify ignore files based on actual project setup:\n-\n-   **Detection & Creation Logic**:\n-   - Check if the following command succeeds to determine if the repository is a git repo (create/verify .gitignore if so):\n-\n-     ```sh\n-     git rev-parse --git-dir 2>/dev/null\n-     ```\n-\n-   - Check if Dockerfile* exists or Docker in plan.md ΓåÆ create/verify .dockerignore\n-   - Check if .eslintrc* exists ΓåÆ create/verify .eslintignore\n-   - Check if eslint.config.* exists ΓåÆ ensure the config's `ignores` entries cover required patterns\n-   - Check if .prettierrc* exists ΓåÆ create/verify .prettierignore\n-   - Check if .npmrc or package.json exists ΓåÆ create/verify .npmignore (if publishing)\n-   - Check if terraform files (*.tf) exist ΓåÆ create/verify .terraformignore\n-   - Check if .helmignore needed (helm charts present) ΓåÆ create/verify .helmignore\n-\n-   **If ignore file already exists**: Verify it contains essential patterns, append missing critical patterns only\n-   **If ignore file missing**: Create with full pattern set for detected technology\n-\n-   **Common Patterns by Technology** (from plan.md tech stack):\n-   - **Node.js/JavaScript/TypeScript**: `node_modules/`, `dist/`, `build/`, `*.log`, `.env*`\n-   - **Python**: `__pycache__/`, `*.pyc`, `.venv/`, `venv/`, `dist/`, `*.egg-info/`\n-   - **Java**: `target/`, `*.class`, `*.jar`, `.gradle/`, `build/`\n-   - **C#/.NET**: `bin/`, `obj/`, `*.user`, `*.suo`, `packages/`\n-   - **Go**: `*.exe`, `*.test`, `vendor/`, `*.out`\n-   - **Ruby**: `.bundle/`, `log/`, `tmp/`, `*.gem`, `vendor/bundle/`\n-   - **PHP**: `vendor/`, `*.log`, `*.cache`, `*.env`\n-   - **Rust**: `target/`, `debug/`, `release/`, `*.rs.bk`, `*.rlib`, `*.prof*`, `.idea/`, `*.log`, `.env*`\n-   - **Kotlin**: `build/`, `out/`, `.gradle/`, `.idea/`, `*.class`, `*.jar`, `*.iml`, `*.log`, `.env*`\n-   - **C++**: `build/`, `bin/`, `obj/`, `out/`, `*.o`, `*.so`, `*.a`, `*.exe`, `*.dll`, `.idea/`, `*.log`, `.env*`\n-   - **C**: `build/`, `bin/`, `obj/`, `out/`, `*.o`, `*.a`, `*.so`, `*.exe`, `Makefile`, `config.log`, `.idea/`, `*.log`, `.env*`\n-   - **Swift**: `.build/`, `DerivedData/`, `*.swiftpm/`, `Packages/`\n-   - **R**: `.Rproj.user/`, `.Rhistory`, `.RData`, `.Ruserdata`, `*.Rproj`, `packrat/`, `renv/`\n-   - **Universal**: `.DS_Store`, `Thumbs.db`, `*.tmp`, `*.swp`, `.vscode/`, `.idea/`\n-\n-   **Tool-Specific Patterns**:\n-   - **Docker**: `node_modules/`, `.git/`, `Dockerfile*`, `.dockerignore`, `*.log*`, `.env*`, `coverage/`\n-   - **ESLint**: `node_modules/`, `dist/`, `build/`, `coverage/`, `*.min.js`\n-   - **Prettier**: `node_modules/`, `dist/`, `build/`, `coverage/`, `package-lock.json`, `yarn.lock`, `pnpm-lock.yaml`\n-   - **Terraform**: `.terraform/`, `*.tfstate*`, `*.tfvars`, `.terraform.lock.hcl`\n-   - **Kubernetes/k8s**: `*.secret.yaml`, `secrets/`, `.kube/`, `kubeconfig*`, `*.key`, `*.crt`\n-\n-5. Parse tasks.md structure and extract:\n-   - **Task phases**: Setup, Tests, Core, Integration, Polish\n-   - **Task dependencies**: Sequential vs parallel execution rules\n-   - **Task details**: ID, description, file paths, parallel markers [P]\n-   - **Execution flow**: Order and dependency requirements\n-\n-6. Execute implementation following the task plan:\n-   - **Phase-by-phase execution**: Complete each phase before moving to the next\n-   - **Respect dependencies**: Run sequential tasks in order, parallel tasks [P] can run together  \n-   - **Follow TDD approach**: Execute test tasks before their corresponding implementation tasks\n-   - **File-based coordination**: Tasks affecting the same files must run sequentially\n-   - **Validation checkpoints**: Verify each phase completion before proceeding\n-\n-7. Implementation execution rules:\n-   - **Setup first**: Initialize project structure, dependencies, configuration\n-   - **Tests before code**: Write tests that implement test case IDs from test-cases.md before implementation\n-   - **Reference test cases**: Each test should document which test case ID(s) it implements (e.g., `// Implements: UX-001, EH-003`)\n-   - **When tests fail**: Follow the **Test Integrity Protocol** - assume code is wrong, not test. Never weaken assertions without user approval.\n-   - **Core development**: Implement models, services, CLI commands, endpoints\n-   - **Integration work**: Database connections, middleware, logging, external services\n-   - **Polish and validation**: Unit tests, performance optimization, documentation\n-\n-8. Progress tracking and error handling:\n-   - **ΓÜá∩╕Å CRITICAL**: Mark each task complete (`- [X]`) in tasks.md **immediately** after completing it - do this BEFORE moving to the next task\n-   - **Test tasks are atomic**: Each test task implements exactly ONE test case ID, so completion is unambiguous\n-   - **Do NOT pause** to report progress - keep executing until blocked or done\n-   - Halt execution only if a blocking error prevents continuation\n-   - For parallel tasks [P], continue with successful tasks, note failed ones\n-   - If implementation cannot proceed, provide clear error context and suggest resolution\n-\n-9. Completion validation:\n-   - Verify all required tasks are completed - no tasks should be considered optional or deferrable\n-   - Check that implemented features match the original specification\n-   - Validate that tests pass and coverage meets requirements\n-   - Verify all test case IDs from test-cases.md are implemented by at least one test\n-   - Confirm the implementation follows the technical plan\n-   - Report final status with summary of completed work and test case coverage\n-\n-Note: This command assumes a complete task breakdown exists in tasks.md. If tasks are incomplete or missing, suggest running `/speckit.tasks` first to regenerate the task list.\n-\n-**REMINDER**: Follow the **Decision Point Protocol** (above) whenever you encounter gaps requiring assumption. Do not proceed past meaningful ambiguity without user input.\ndiff --git a/.claude/commands/speckit.tasks.md b/.claude/commands/speckit.tasks.md\nindex 30686bf..6bfddb3 100644\n--- a/.claude/commands/speckit.tasks.md\n+++ b/.claude/commands/speckit.tasks.md\n@@ -1,13 +1,13 @@\n ---\n-description: Generate an actionable, dependency-ordered tasks.md for the feature based on available design artifacts.\n+description: Generate an actionable, dependency-ordered tasks.md for the feature based on available design artifacts. Tasks are atomic Micro-TDD units.\n handoffs: \n-  - label: Analyze For Consistency\n+  - label: Analyze Workflow\n     agent: speckit.analyze\n-    prompt: Run a project analysis for consistency\n+    prompt: Validate task format and test case coverage\n     send: true\n-  - label: Implement Project\n-    agent: speckit.implement\n-    prompt: Start the implementation in phases\n+  - label: Create Batches\n+    agent: speckit.batch\n+    prompt: Create task batches for bounded execution\n     send: true\n ---\n \n@@ -70,94 +70,97 @@ The tasks.md should be immediately executable - each task must be specific enoug\n \n ## Task Generation Rules\n \n-**CRITICAL**: Tasks MUST be organized by user story to enable independent implementation and testing.\n+**CRITICAL**: Each task is an ATOMIC Micro-TDD unit ΓÇö ONE test case, ONE behavioral change.\n \n-**Tests are not OPTIONAL**: The constitution enforces a strict TDD approach.\n+**Tests are not OPTIONAL**: The constitution enforces strict TDD. Every task includes both test and implementation as a single behavioral unit.\n \n-**Test cases drive test tasks**: Each test task must reference one or more test case IDs from test-cases.md. This ensures comprehensive coverage of UX, component, data flow, and error handling validation.\n+**Test cases drive tasks**: Each task implements exactly ONE test case from test-cases.md. The task IS the behavioral unit (test + implementation together).\n \n ### Checklist Format (REQUIRED)\n \n Every task MUST strictly follow this format:\n \n ```text\n-- [ ] [TaskID] [P?] [Story?] Description with file path\n+- [ ] T### [depends:T###,T###] @test-case:XX-### Description with file path\n ```\n \n **Format Components**:\n \n 1. **Checkbox**: ALWAYS start with `- [ ]` (markdown checkbox)\n-2. **Task ID**: Sequential number (T001, T002, T003...) in execution order\n-3. **[P] marker**: Include ONLY if task is parallelizable (different files, no dependencies on incomplete tasks)\n-4. **[Story] label**: REQUIRED for user story phase tasks only\n-   - Format: [US1], [US2], [US3], etc. (maps to user stories from spec.md)\n-   - Setup phase: NO story label\n-   - Foundational phase: NO story label  \n-   - User Story phases: MUST have story label\n-   - Polish phase: NO story label\n+2. **Task ID**: Sequential number (T001, T002, T003...) globally unique\n+3. **Dependencies**: `[depends:T001,T002]` ΓÇö tasks that must complete first (optional, omit if none)\n+4. **Test Case**: `@test-case:UX-001` ΓÇö REQUIRED, exactly ONE test case ID from test-cases.md\n 5. **Description**: Clear action with exact file path\n \n **Examples**:\n \n-- Γ£à CORRECT: `- [ ] T001 Create project structure per implementation plan`\n-- Γ£à CORRECT: `- [ ] T005 [P] Implement authentication middleware in src/middleware/auth.py`\n-- Γ£à CORRECT: `- [ ] T012 [P] [US1] Create User model in src/models/user.py`\n-- Γ£à CORRECT: `- [ ] T014 [US1] Implement UserService in src/services/user_service.py`\n-- Γ¥î WRONG: `- [ ] Create User model` (missing ID and Story label)\n-- Γ¥î WRONG: `T001 [US1] Create model` (missing checkbox)\n-- Γ¥î WRONG: `- [ ] [US1] Create User model` (missing Task ID)\n-- Γ¥î WRONG: `- [ ] T001 [US1] Create model` (missing file path)\n+- Γ£à CORRECT: `- [ ] T001 @test-case:UX-001 Implement single file download in FileTransferService.cs`\n+- Γ£à CORRECT: `- [ ] T005 [depends:T001] @test-case:UX-002 Add glob pattern support to DownloadCommand.cs`\n+- Γ£à CORRECT: `- [ ] T012 [depends:T005,T006] @test-case:CV-001 Validate path traversal prevention in PathValidator.cs`\n+- Γ¥î WRONG: `- [ ] T001 Create download command` (missing @test-case)\n+- Γ¥î WRONG: `- [ ] T001 @test-case:UX-001,UX-002 Multiple behaviors` (multiple test cases ΓÇö split into separate tasks)\n+- Γ¥î WRONG: `- [ ] T001 [P] @test-case:UX-001 Description` ([P] marker is obsolete ΓÇö use [depends:] instead)\n+\n+**IMPORTANT**: The old `[P]` (parallel) and `[US#]` (user story) markers are REMOVED. Dependencies are explicit via `[depends:]`. Story organization is informational only.\n+\n+### Task Sizing Rules\n+\n+Each task must be **Micro-TDD sized**:\n+\n+1. **ONE test case** ΓÇö maps to exactly one test case ID from test-cases.md\n+2. **ONE behavioral change** ΓÇö implements one \"When X, Then Y\" from the test case\n+3. **ONE redΓåÆgreen cycle** ΓÇö agent writes test, sees it fail, implements, sees it pass\n+\n+If a task seems to need multiple tests, it's too large. Split it.\n \n ### Task Organization\n \n-1. **From User Stories (spec.md)** - PRIMARY ORGANIZATION:\n-   - Each user story (P1, P2, P3...) gets its own phase\n-   - Map all related components to their story:\n-     - Models needed for that story\n-     - Services needed for that story\n-     - Endpoints/UI needed for that story\n-     - Tests for that story (reference test case IDs: UX-xxx, CV-xxx, etc.)\n-   - Mark story dependencies (most stories should be independent)\n-\n-2. **From Contracts**:\n-   - Map each contract/endpoint ΓåÆ to the user story it serves\n-   - Each contract ΓåÆ contract test task [P] before implementation in that story's phase\n-\n-3. **From Data Model**:\n-   - Map each entity to the user story(ies) that need it\n-   - If entity serves multiple stories: Put in earliest story or Setup phase\n-   - Relationships ΓåÆ service layer tasks in appropriate story phase\n-\n-4. **From Test Cases (test-cases.md)** - REQUIRED:\n-   - **ONE test case ID per test task** - do not bundle multiple IDs into a single task\n-   - Map each test case ID to exactly one test task\n-   - UX test cases (UX-xxx) ΓåÆ integration/acceptance test tasks\n-   - Component test cases (CV-xxx) ΓåÆ unit test tasks\n-   - Data flow test cases (DF-xxx) ΓåÆ integration test tasks\n-   - Error handling test cases (EH-xxx) ΓåÆ unit or integration test tasks\n-   - Test task description should include: \"(implements {single test case ID})\"\n-   - Example: `- [ ] T010 [P] [US1] Test UploadCommand connection check (implements UX-001)`\n-   - Example: `- [ ] T011 [P] [US1] Test UploadCommand returns error when disconnected (implements EH-001)`\n-   - This ensures atomic task completion - no partial coverage, no verification overhead\n-\n-   **Test Pattern Awareness**:\n-   - Before generating test tasks, identify existing test files for the component being extended\n-   - Reference existing test patterns in task descriptions when applicable\n-   - Example: `- [ ] T012 [P] [US1] Test PathValidator rejects traversal (implements CV-002, pattern: see PathValidationTests.cs)`\n-   - For platform-sensitive features (paths, file I/O, environment), explicitly note if cross-platform testing is needed\n-   - Example: `- [ ] T015 [P] [US1] Test path handling for Unix-style paths on Windows (implements EH-005, cross-platform)`\n-\n-5. **From Setup/Infrastructure**:\n-   - Shared infrastructure ΓåÆ Setup phase (Phase 1)\n-   - Foundational/blocking tasks ΓåÆ Foundational phase (Phase 2)\n-   - Story-specific setup ΓåÆ within that story's phase\n-\n-### Phase Structure\n-\n-- **Phase 1**: Setup (project initialization)\n-- **Phase 2**: Foundational (blocking prerequisites - MUST complete before user stories)\n-- **Phase 3+**: User Stories in priority order (P1, P2, P3...)\n-  - Within each story: Tests FIRST (TDD) ΓåÆ Models ΓåÆ Services ΓåÆ Endpoints ΓåÆ Integration\n-  - Each test task references test case IDs it implements\n-  - Each phase should be a complete, independently testable increment\n-- **Final Phase**: Polish & Cross-Cutting Concerns\n+1. **From User Stories (spec.md)** - GROUP by story for readability:\n+   - Each user story (P1, P2, P3...) is documented as a section\n+   - Tasks within a story section implement that story's test cases\n+   - Stories are informational grouping ΓÇö dependencies are explicit via `[depends:]`\n+\n+2. **From Test Cases (test-cases.md)** - ONE TASK per test case:\n+   - Each test case ID (UX-xxx, CV-xxx, DF-xxx, EH-xxx) becomes exactly ONE task\n+   - The task's `@test-case:` reference is the test case ID\n+   - No bundling multiple test cases into one task\n+   - No test case without a corresponding task\n+\n+3. **Dependencies via `[depends:]`**:\n+   - If task B requires task A's implementation, use `[depends:T001]`\n+   - Multiple dependencies: `[depends:T001,T002,T003]`\n+   - Dependencies are verified before task becomes eligible for execution\n+\n+4. **From Data Model**:\n+   - Each entity/model that needs implementation gets tasks\n+   - Map entities to the test cases that require them\n+   - Use dependencies to ensure models exist before services that use them\n+\n+5. **From Contracts**:\n+   - Each endpoint/API contract maps to test cases\n+   - Implementation tasks depend on model/service tasks\n+\n+6. **Setup/Infrastructure** (no test case required):\n+   - Project setup tasks (create files, configure dependencies) may use `@test-case:SETUP-###`\n+   - These are the only tasks without behavioral test cases\n+   - Keep setup tasks minimal ΓÇö prefer tasks with real test cases\n+\n+### Output Structure\n+\n+The generated tasks.md should have:\n+\n+1. **Header**: Feature name, prerequisites, format reference\n+2. **Setup Section**: Infrastructure tasks (if any)\n+3. **User Story Sections**: Grouped by story for readability\n+   - Each task has explicit `@test-case:` and `[depends:]`\n+4. **Summary**: Total tasks, test case coverage validation\n+\n+### Validation Before Output\n+\n+Before finalizing tasks.md, verify:\n+\n+- [ ] Every test case from test-cases.md has exactly ONE task\n+- [ ] Every task (except setup) has exactly ONE `@test-case:` reference\n+- [ ] Dependencies form a valid DAG (no circular dependencies)\n+- [ ] Task IDs are sequential and unique (T001, T002, ...)\n+- [ ] Each task has a clear file path in description\ndiff --git a/.specify/templates/tasks-template.md b/.specify/templates/tasks-template.md\nindex 60f9be4..3d5a31b 100644\n--- a/.specify/templates/tasks-template.md\n+++ b/.specify/templates/tasks-template.md\n@@ -1,22 +1,31 @@\n ---\n \n-description: \"Task list template for feature implementation\"\n+description: \"Task list template for feature implementation - Micro-TDD format\"\n ---\n \n # Tasks: [FEATURE NAME]\n \n **Input**: Design documents from `/specs/[###-feature-name]/`\n-**Prerequisites**: plan.md (required), spec.md (required for user stories), research.md, data-model.md, contracts/\n+**Prerequisites**: plan.md (required), spec.md (required for user stories), test-cases.md (required), data-model.md, contracts/\n \n-**Tests**: The examples below include test tasks. Tests are OPTIONAL - only include them if explicitly requested in the feature specification.\n+**Micro-TDD Format**: Each task is an atomic behavioral unit ΓÇö ONE test case, ONE redΓåÆgreen cycle.\n \n-**Organization**: Tasks are grouped by user story to enable independent implementation and testing of each story.\n+**Organization**: Tasks are grouped by user story for readability. Dependencies are explicit via `[depends:]`.\n \n-## Format: `[ID] [P?] [Story] Description`\n+## Task Format\n \n-- **[P]**: Can run in parallel (different files, no dependencies)\n-- **[Story]**: Which user story this task belongs to (e.g., US1, US2, US3)\n-- Include exact file paths in descriptions\n+```text\n+- [ ] T### [depends:T###,T###] @test-case:XX-### Description with file path\n+```\n+\n+**Components**:\n+- **Checkbox**: `- [ ]` (markdown checkbox, marked when completed)\n+- **Task ID**: Sequential (T001, T002, T003...) ΓÇö globally unique\n+- **Dependencies**: `[depends:T001,T002]` ΓÇö tasks that must complete first (omit if none)\n+- **Test Case**: `@test-case:UX-001` ΓÇö REQUIRED, exactly ONE test case ID from test-cases.md\n+- **Description**: Clear action with exact file path\n+\n+**Task Sizing**: Each task = ONE test case = ONE behavioral change = ONE redΓåÆgreen cycle\n \n ## Path Conventions\n \n@@ -30,115 +39,77 @@ description: \"Task list template for feature implementation\"\n   IMPORTANT: The tasks below are SAMPLE TASKS for illustration purposes only.\n   \n   The /speckit.tasks command MUST replace these with actual tasks based on:\n-  - User stories from spec.md (with their priorities P1, P2, P3...)\n+  - Test cases from test-cases.md (each test case ΓåÆ ONE task)\n+  - User stories from spec.md (for grouping/readability)\n   - Feature requirements from plan.md\n   - Entities from data-model.md\n   - Endpoints from contracts/\n   \n-  Tasks MUST be organized by user story so each story can be:\n-  - Implemented independently\n-  - Tested independently\n-  - Delivered as an MVP increment\n+  Every task MUST have exactly ONE @test-case: reference.\n+  Dependencies MUST be explicit via [depends:].\n   \n   DO NOT keep these sample tasks in the generated tasks.md file.\n   ============================================================================\n -->\n \n-## Phase 1: Setup (Shared Infrastructure)\n+## Phase 1: Setup (Infrastructure)\n \n-**Purpose**: Project initialization and basic structure\n+**Purpose**: Project initialization and basic structure ΓÇö no behavioral test cases\n \n-- [ ] T001 Create project structure per implementation plan\n-- [ ] T002 Initialize [language] project with [framework] dependencies\n-- [ ] T003 [P] Configure linting and formatting tools\n+- [ ] T001 @test-case:SETUP-001 Create project structure per implementation plan\n+- [ ] T002 [depends:T001] @test-case:SETUP-002 Initialize [language] project with [framework] dependencies\n+- [ ] T003 [depends:T001] @test-case:SETUP-003 Configure linting and formatting tools\n \n ---\n \n-## Phase 2: Foundational (Blocking Prerequisites)\n-\n-**Purpose**: Core infrastructure that MUST be complete before ANY user story can be implemented\n-\n-**ΓÜá∩╕Å CRITICAL**: No user story work can begin until this phase is complete\n-\n-Examples of foundational tasks (adjust based on your project):\n-\n-- [ ] T004 Setup database schema and migrations framework\n-- [ ] T005 [P] Implement authentication/authorization framework\n-- [ ] T006 [P] Setup API routing and middleware structure\n-- [ ] T007 Create base models/entities that all stories depend on\n-- [ ] T008 Configure error handling and logging infrastructure\n-- [ ] T009 Setup environment configuration management\n-\n-**Checkpoint**: Foundation ready - user story implementation can now begin in parallel\n-\n----\n-\n-## Phase 3: User Story 1 - [Title] (Priority: P1) ≡ƒÄ» MVP\n+## Phase 2: User Story 1 - [Title] (Priority: P1) ≡ƒÄ» MVP\n \n **Goal**: [Brief description of what this story delivers]\n \n-**Independent Test**: [How to verify this story works on its own]\n-\n-### Tests for User Story 1 (OPTIONAL - only if tests requested) ΓÜá∩╕Å\n+**Test Cases**: UX-001 through UX-003, CV-001, EH-001\n \n-> **NOTE: Write these tests FIRST, ensure they FAIL before implementation**\n+### Tasks\n \n-- [ ] T010 [P] [US1] Contract test for [endpoint] in tests/contract/test_[name].py\n-- [ ] T011 [P] [US1] Integration test for [user journey] in tests/integration/test_[name].py\n+- [ ] T004 [depends:T002] @test-case:UX-001 Implement basic [action] in src/services/[service].py\n+- [ ] T005 [depends:T004] @test-case:UX-002 Add [secondary behavior] to [service].py\n+- [ ] T006 [depends:T004] @test-case:CV-001 Validate [input] in src/validators/[validator].py\n+- [ ] T007 [depends:T004] @test-case:EH-001 Handle [error condition] in [service].py\n+- [ ] T008 [depends:T005,T006,T007] @test-case:UX-003 Integrate [feature] endpoint in src/api/[endpoint].py\n \n-### Implementation for User Story 1\n-\n-- [ ] T012 [P] [US1] Create [Entity1] model in src/models/[entity1].py\n-- [ ] T013 [P] [US1] Create [Entity2] model in src/models/[entity2].py\n-- [ ] T014 [US1] Implement [Service] in src/services/[service].py (depends on T012, T013)\n-- [ ] T015 [US1] Implement [endpoint/feature] in src/[location]/[file].py\n-- [ ] T016 [US1] Add validation and error handling\n-- [ ] T017 [US1] Add logging for user story 1 operations\n-\n-**Checkpoint**: At this point, User Story 1 should be fully functional and testable independently\n+**Checkpoint**: User Story 1 complete ΓÇö all tests pass, feature independently usable\n \n ---\n \n-## Phase 4: User Story 2 - [Title] (Priority: P2)\n+## Phase 3: User Story 2 - [Title] (Priority: P2)\n \n **Goal**: [Brief description of what this story delivers]\n \n-**Independent Test**: [How to verify this story works on its own]\n-\n-### Tests for User Story 2 (OPTIONAL - only if tests requested) ΓÜá∩╕Å\n+**Test Cases**: UX-004 through UX-006, DF-001\n \n-- [ ] T018 [P] [US2] Contract test for [endpoint] in tests/contract/test_[name].py\n-- [ ] T019 [P] [US2] Integration test for [user journey] in tests/integration/test_[name].py\n+### Tasks\n \n-### Implementation for User Story 2\n+- [ ] T009 [depends:T002] @test-case:UX-004 Implement [action] in src/services/[service2].py\n+- [ ] T010 [depends:T009] @test-case:UX-005 Add [behavior] to [service2].py\n+- [ ] T011 [depends:T009] @test-case:DF-001 Connect [service2] to [data store]\n+- [ ] T012 [depends:T010,T011] @test-case:UX-006 Expose [feature] via endpoint\n \n-- [ ] T020 [P] [US2] Create [Entity] model in src/models/[entity].py\n-- [ ] T021 [US2] Implement [Service] in src/services/[service].py\n-- [ ] T022 [US2] Implement [endpoint/feature] in src/[location]/[file].py\n-- [ ] T023 [US2] Integrate with User Story 1 components (if needed)\n-\n-**Checkpoint**: At this point, User Stories 1 AND 2 should both work independently\n+**Checkpoint**: User Story 2 complete ΓÇö can work independently of Story 1\n \n ---\n \n-## Phase 5: User Story 3 - [Title] (Priority: P3)\n+## Phase 4: User Story 3 - [Title] (Priority: P3)\n \n **Goal**: [Brief description of what this story delivers]\n \n-**Independent Test**: [How to verify this story works on its own]\n-\n-### Tests for User Story 3 (OPTIONAL - only if tests requested) ΓÜá∩╕Å\n+**Test Cases**: UX-007, CV-002, EH-002\n \n-- [ ] T024 [P] [US3] Contract test for [endpoint] in tests/contract/test_[name].py\n-- [ ] T025 [P] [US3] Integration test for [user journey] in tests/integration/test_[name].py\n+### Tasks\n \n-### Implementation for User Story 3\n+- [ ] T013 [depends:T002] @test-case:UX-007 Implement [action] in src/services/[service3].py\n+- [ ] T014 [depends:T013] @test-case:CV-002 Validate [complex input] in [validator].py\n+- [ ] T015 [depends:T013] @test-case:EH-002 Handle [edge case] gracefully\n \n-- [ ] T026 [P] [US3] Create [Entity] model in src/models/[entity].py\n-- [ ] T027 [US3] Implement [Service] in src/services/[service].py\n-- [ ] T028 [US3] Implement [endpoint/feature] in src/[location]/[file].py\n-\n-**Checkpoint**: All user stories should now be independently functional\n+**Checkpoint**: User Story 3 complete ΓÇö all three stories independently functional\n \n ---\n \n@@ -146,7 +117,12 @@ Examples of foundational tasks (adjust based on your project):\n \n ---\n \n-## Phase N: Polish & Cross-Cutting Concerns\n+## Phase N: Integration & Cross-Cutting\n+\n+**Purpose**: Cross-story integration that wasn't covered in individual stories\n+\n+- [ ] TXXX [depends:T008,T012,T015] @test-case:DF-002 Integration between Story 1 and Story 2\n+- [ ] TXXX [depends:TXXX] @test-case:CV-003 Cross-cutting validation rules\n \n **Purpose**: Improvements that affect multiple user stories\n \n@@ -161,91 +137,103 @@ Examples of foundational tasks (adjust based on your project):\n \n ## Dependencies & Execution Order\n \n-### Phase Dependencies\n+### Dependency Resolution\n \n-- **Setup (Phase 1)**: No dependencies - can start immediately\n-- **Foundational (Phase 2)**: Depends on Setup completion - BLOCKS all user stories\n-- **User Stories (Phase 3+)**: All depend on Foundational phase completion\n-  - User stories can then proceed in parallel (if staffed)\n-  - Or sequentially in priority order (P1 ΓåÆ P2 ΓåÆ P3)\n-- **Polish (Final Phase)**: Depends on all desired user stories being complete\n+Dependencies are explicit in each task via `[depends:T###]`. The workflow engine:\n \n-### User Story Dependencies\n+1. Parses all tasks and builds a dependency graph (DAG)\n+2. Topologically sorts tasks to determine execution order\n+3. A task is only eligible when all its dependencies are completed\n+4. Batches group eligible tasks for bounded execution (10-15 per batch)\n \n-- **User Story 1 (P1)**: Can start after Foundational (Phase 2) - No dependencies on other stories\n-- **User Story 2 (P2)**: Can start after Foundational (Phase 2) - May integrate with US1 but should be independently testable\n-- **User Story 3 (P3)**: Can start after Foundational (Phase 2) - May integrate with US1/US2 but should be independently testable\n+### Batch Execution Model\n \n-### Within Each User Story\n+- **Batch 1**: Setup tasks + initial story tasks without dependencies\n+- **Batch 2**: Tasks whose dependencies were satisfied in Batch 1\n+- **Batch N**: Continues until all tasks complete\n \n-- Tests (if included) MUST be written and FAIL before implementation\n-- Models before services\n-- Services before endpoints\n-- Core implementation before integration\n-- Story complete before moving to next priority\n+Each batch is:\n+- Created by `/speckit.batch`\n+- Executed via `/speckit.execute` (one task at a time)\n+- Verified via `/speckit.verify` (mandatory gate)\n \n-### Parallel Opportunities\n+### Within Each Task (Micro-TDD Cycle)\n \n-- All Setup tasks marked [P] can run in parallel\n-- All Foundational tasks marked [P] can run in parallel (within Phase 2)\n-- Once Foundational phase completes, all user stories can start in parallel (if team capacity allows)\n-- All tests for a user story marked [P] can run in parallel\n-- Models within a story marked [P] can run in parallel\n-- Different user stories can be worked on in parallel by different team members\n+1. **Write Test**: Create test for the @test-case behavior\n+2. **Red Phase**: Run test, capture failure output as evidence\n+3. **Implement**: Write minimal code to make test pass\n+4. **Green Phase**: Run test, capture success output as evidence\n+5. **Verify**: Script validates evidence before task completes\n \n----\n+### Story Independence\n+\n+- User stories are grouped for readability only\n+- Actual execution order comes from `[depends:]` constraints\n+- Each story's tasks can interleave with others if dependencies allow\n+- Checkpoints mark when a story's tasks are all complete\n \n-## Parallel Example: User Story 1\n+---\n \n-```bash\n-# Launch all tests for User Story 1 together (if tests requested):\n-Task: \"Contract test for [endpoint] in tests/contract/test_[name].py\"\n-Task: \"Integration test for [user journey] in tests/integration/test_[name].py\"\n+## Batch Example\n \n-# Launch all models for User Story 1 together:\n-Task: \"Create [Entity1] model in src/models/[entity1].py\"\n-Task: \"Create [Entity2] model in src/models/[entity2].py\"\n+Given these tasks:\n+```text\n+- [ ] T001 @test-case:SETUP-001 Create project structure\n+- [ ] T002 [depends:T001] @test-case:SETUP-002 Add dependencies\n+- [ ] T003 [depends:T001] @test-case:UX-001 Implement feature A\n+- [ ] T004 [depends:T002,T003] @test-case:UX-002 Integrate A with deps\n ```\n \n+Batch creation produces:\n+- **Batch 1**: T001 (no dependencies)\n+- **Batch 2**: T002, T003 (both depend only on T001)\n+- **Batch 3**: T004 (depends on T002 and T003)\n+\n ---\n \n ## Implementation Strategy\n \n ### MVP First (User Story 1 Only)\n \n-1. Complete Phase 1: Setup\n-2. Complete Phase 2: Foundational (CRITICAL - blocks all stories)\n-3. Complete Phase 3: User Story 1\n-4. **STOP and VALIDATE**: Test User Story 1 independently\n-5. Deploy/demo if ready\n+1. Complete Setup tasks (batch includes T001-T003)\n+2. Complete User Story 1 tasks\n+3. **STOP and VALIDATE**: All Story 1 tests pass\n+4. Deploy/demo if ready ΓÇö remaining stories are additive\n \n ### Incremental Delivery\n \n-1. Complete Setup + Foundational ΓåÆ Foundation ready\n-2. Add User Story 1 ΓåÆ Test independently ΓåÆ Deploy/Demo (MVP!)\n-3. Add User Story 2 ΓåÆ Test independently ΓåÆ Deploy/Demo\n-4. Add User Story 3 ΓåÆ Test independently ΓåÆ Deploy/Demo\n-5. Each story adds value without breaking previous stories\n+1. Setup ΓåÆ Story 1 ΓåÆ Deploy/Demo (MVP!)\n+2. Add Story 2 ΓåÆ Deploy/Demo\n+3. Add Story 3 ΓåÆ Deploy/Demo\n+4. Each increment adds value without breaking previous work\n+\n+### Bounded Execution\n+\n+- Each `/speckit.execute` processes ONE task\n+- Each `/speckit.verify` validates that ONE task\n+- Batches limit scope to 10-15 tasks\n+- Agent never sees future batches (prevents over-design)\n+\n+---\n+\n+## Test Case Validation\n \n-### Parallel Team Strategy\n+Before generating final tasks.md, verify:\n \n-With multiple developers:\n+- [ ] Every test case ID in test-cases.md has exactly ONE task\n+- [ ] Every task has exactly ONE @test-case: reference\n+- [ ] Dependencies form a valid DAG (no cycles)\n+- [ ] Task IDs are sequential and unique\n+- [ ] Each task has a clear file path\n \n-1. Team completes Setup + Foundational together\n-2. Once Foundational is done:\n-   - Developer A: User Story 1\n-   - Developer B: User Story 2\n-   - Developer C: User Story 3\n-3. Stories complete and integrate independently\n+Run `/speckit.analyze` to validate before batching.\n \n ---\n \n ## Notes\n \n-- [P] tasks = different files, no dependencies\n-- [Story] label maps task to specific user story for traceability\n-- Each user story should be independently completable and testable\n-- Verify tests fail before implementing\n-- Commit after each task or logical group\n-- Stop at any checkpoint to validate story independently\n-- Avoid: vague tasks, same file conflicts, cross-story dependencies that break independence\n+- `[depends:]` replaces the old `[P]` parallel marker ΓÇö dependencies are explicit\n+- Story labels (US1, US2) are REMOVED ΓÇö use story sections for grouping\n+- Each task = ONE test case = ONE redΓåÆgreen cycle\n+- Evidence files capture red and green outputs for verification\n+- Commit after each verified task or batch completion\ndiff --git a/BitPantry.CommandLine.Remote.SignalR.Client/Commands/Server/DownloadCommand.cs b/BitPantry.CommandLine.Remote.SignalR.Client/Commands/Server/DownloadCommand.cs\nindex 0242a73..92d5d6f 100644\n--- a/BitPantry.CommandLine.Remote.SignalR.Client/Commands/Server/DownloadCommand.cs\n+++ b/BitPantry.CommandLine.Remote.SignalR.Client/Commands/Server/DownloadCommand.cs\n@@ -300,22 +300,17 @@ namespace BitPantry.CommandLine.Remote.SignalR.Client.Commands.Server\n             var files = await _fileTransferService.EnumerateFiles(baseDir, searchPattern, recursive, cancellationToken);\n \n             // If pattern contains ?, apply regex post-filtering (FileSystemGlobbing doesn't support ?)\n-            if (searchPattern.Contains('?'))\n-            {\n-                var regex = GlobPatternHelper.GlobPatternToRegex(searchPattern);\n-                files = files.Where(f => regex.IsMatch(_fileSystem.Path.GetFileName(f.Path))).ToArray();\n-            }\n+            files = GlobPatternHelper.ApplyQuestionMarkFilter(\n+                files, \n+                searchPattern, \n+                f => _fileSystem.Path.GetFileName(f.Path)).ToArray();\n \n             // The server returns relative paths from the search root.\n             // Convert to full server-relative paths by prepending the base directory.\n-            if (!string.IsNullOrEmpty(baseDir) && baseDir != \".\")\n-            {\n-                var baseDirPrefix = baseDir.TrimEnd('/') + \"/\";\n-                files = files.Select(f => new FileInfoEntry(\n-                    baseDirPrefix + f.Path.TrimStart('/'),\n-                    f.Size,\n-                    f.LastModified)).ToArray();\n-            }\n+            files = files.Select(f => new FileInfoEntry(\n+                GlobPatternHelper.ReconstructFullPath(baseDir, f.Path),\n+                f.Size,\n+                f.LastModified)).ToArray();\n \n             return files;\n         }\n@@ -346,14 +341,14 @@ namespace BitPantry.CommandLine.Remote.SignalR.Client.Commands.Server\n         /// <returns>The resolved local file path</returns>\n         public string ResolveLocalPath(string remotePath)\n         {\n+            var fileName = _fileSystem.Path.GetFileName(remotePath);\n+            var resolved = GlobPatternHelper.ResolveDestinationPath(Destination, fileName);\n+            \n+            // Use platform-appropriate path combination for local paths\n             if (Destination.EndsWith('/') || Destination.EndsWith('\\\\'))\n             {\n-                // Destination is a directory - append the filename from remote path\n-                var fileName = _fileSystem.Path.GetFileName(remotePath);\n                 return _fileSystem.Path.Combine(Destination.TrimEnd('/', '\\\\'), fileName);\n             }\n-\n-            // Destination is a specific filename\n             return Destination;\n         }\n \ndiff --git a/BitPantry.CommandLine.Remote.SignalR.Client/Commands/Server/UploadCommand.cs b/BitPantry.CommandLine.Remote.SignalR.Client/Commands/Server/UploadCommand.cs\nindex 45ddfc3..0b0e2ee 100644\n--- a/BitPantry.CommandLine.Remote.SignalR.Client/Commands/Server/UploadCommand.cs\n+++ b/BitPantry.CommandLine.Remote.SignalR.Client/Commands/Server/UploadCommand.cs\n@@ -213,38 +213,29 @@ namespace BitPantry.CommandLine.Remote.SignalR.Client.Commands.Server\n             var directoryInfo = new DirectoryInfo(baseDir);\n             var result = matcher.Execute(new GlobbingDirectoryInfoWrapper(directoryInfo));\n \n-            // If pattern contained ?, apply regex filtering to enforce single-character match\n-            var regex = pattern.Contains('?') ? GlobPatternHelper.GlobPatternToRegex(originalPattern) : null;\n+            // Collect all matching files\n+            var matchedFiles = result.Files\n+                .Select(file => _fileSystem.Path.GetFullPath(_fileSystem.Path.Combine(baseDir, file.Path)))\n+                .ToList();\n \n-            foreach (var file in result.Files)\n-            {\n-                var filePath = _fileSystem.Path.GetFullPath(_fileSystem.Path.Combine(baseDir, file.Path));\n-                \n-                // Apply regex filter if we had ? wildcards\n-                if (regex != null)\n-                {\n-                    var fileName = _fileSystem.Path.GetFileName(filePath);\n-                    if (!regex.IsMatch(fileName))\n-                        continue;\n-                }\n-                \n-                existing.Add(filePath);\n-            }\n+            // Apply ? wildcard filtering using shared helper\n+            var filteredFiles = GlobPatternHelper.ApplyQuestionMarkFilter(\n+                matchedFiles,\n+                originalPattern,\n+                _fileSystem.Path.GetFileName);\n+\n+            existing.AddRange(filteredFiles);\n \n             return (existing, missing);\n         }\n \n         /// <summary>\n-        /// Parses a glob pattern to extract the base directory and pattern portion.\n+        /// Resolves the destination path by appending the source filename if destination ends with a separator.\n         /// </summary>\n         internal string ResolveDestinationPath(string sourcePath)\n         {\n-            // If destination ends with '/', append the source filename\n-            if (Destination.EndsWith('/') || Destination.EndsWith('\\\\'))\n-            {\n-                return Destination.TrimEnd('/', '\\\\') + \"/\" + _fileSystem.Path.GetFileName(sourcePath);\n-            }\n-            return Destination;\n+            var fileName = _fileSystem.Path.GetFileName(sourcePath);\n+            return GlobPatternHelper.ResolveDestinationPath(Destination, fileName);\n         }\n \n         private async Task UploadSingleFileAsync(string filePath, int skippedCount, int oversizedCount, CancellationToken ct)\ndiff --git a/BitPantry.CommandLine.Remote.SignalR.Client/GlobPatternHelper.cs b/BitPantry.CommandLine.Remote.SignalR.Client/GlobPatternHelper.cs\nindex f84baa9..570007b 100644\n--- a/BitPantry.CommandLine.Remote.SignalR.Client/GlobPatternHelper.cs\n+++ b/BitPantry.CommandLine.Remote.SignalR.Client/GlobPatternHelper.cs\n@@ -126,5 +126,66 @@ namespace BitPantry.CommandLine.Remote.SignalR.Client\n             \n             return new Regex($\"^{regexPattern}$\", RegexOptions.IgnoreCase);\n         }\n+\n+        /// <summary>\n+        /// Resolves a destination path by appending the source filename if destination ends with a separator.\n+        /// Used by both UploadCommand and DownloadCommand for consistent path resolution.\n+        /// </summary>\n+        /// <param name=\"destination\">The destination path (directory or file).</param>\n+        /// <param name=\"sourceFileName\">The source file name to append if destination is a directory.</param>\n+        /// <returns>The resolved destination path.</returns>\n+        public static string ResolveDestinationPath(string destination, string sourceFileName)\n+        {\n+            if (destination.EndsWith('/') || destination.EndsWith('\\\\'))\n+            {\n+                // Destination is a directory - append the source filename\n+                return destination.TrimEnd('/', '\\\\') + \"/\" + sourceFileName;\n+            }\n+            // Destination is a specific filename\n+            return destination;\n+        }\n+\n+        /// <summary>\n+        /// Reconstructs a full path by prepending a base directory to a relative path.\n+        /// Normalizes to forward slashes for server-side paths.\n+        /// </summary>\n+        /// <param name=\"baseDir\">The base directory (e.g., \"logs\").</param>\n+        /// <param name=\"relativePath\">The relative path from the base (e.g., \"app.log\").</param>\n+        /// <returns>The reconstructed full path (e.g., \"logs/app.log\").</returns>\n+        public static string ReconstructFullPath(string baseDir, string relativePath)\n+        {\n+            if (string.IsNullOrEmpty(baseDir) || baseDir == \".\")\n+            {\n+                return relativePath;\n+            }\n+            \n+            var baseDirNormalized = baseDir.Replace('\\\\', '/').TrimEnd('/');\n+            var relativePathNormalized = relativePath.TrimStart('/');\n+            return baseDirNormalized + \"/\" + relativePathNormalized;\n+        }\n+\n+        /// <summary>\n+        /// Filters a collection of file entries using a question-mark wildcard pattern.\n+        /// Microsoft.Extensions.FileSystemGlobbing does NOT support ? wildcards, so this\n+        /// applies regex post-filtering for single-character matching.\n+        /// </summary>\n+        /// <typeparam name=\"T\">The type of file entry.</typeparam>\n+        /// <param name=\"files\">The files to filter.</param>\n+        /// <param name=\"pattern\">The glob pattern containing ? wildcards.</param>\n+        /// <param name=\"getFileName\">Function to extract filename from the entry.</param>\n+        /// <returns>Filtered collection matching the ? wildcard pattern.</returns>\n+        public static IEnumerable<T> ApplyQuestionMarkFilter<T>(\n+            IEnumerable<T> files, \n+            string pattern, \n+            Func<T, string> getFileName)\n+        {\n+            if (!pattern.Contains('?'))\n+            {\n+                return files;\n+            }\n+\n+            var regex = GlobPatternToRegex(pattern);\n+            return files.Where(f => regex.IsMatch(getFileName(f)));\n+        }\n     }\n }\ndiff --git a/BitPantry.CommandLine.Tests.Remote.SignalR/ClientTests/DownloadCommandTests.cs b/BitPantry.CommandLine.Tests.Remote.SignalR/ClientTests/DownloadCommandTests.cs\nindex 1aea2eb..156c5ca 100644\n--- a/BitPantry.CommandLine.Tests.Remote.SignalR/ClientTests/DownloadCommandTests.cs\n+++ b/BitPantry.CommandLine.Tests.Remote.SignalR/ClientTests/DownloadCommandTests.cs\n@@ -5,10 +5,16 @@ using BitPantry.CommandLine.Processing.Execution;\n using BitPantry.CommandLine.Remote.SignalR.Client;\n using BitPantry.CommandLine.Remote.SignalR.Client.Commands.Server;\n using BitPantry.CommandLine.Remote.SignalR.Envelopes;\n+using BitPantry.CommandLine.Tests.Remote.SignalR.Helpers;\n+using BitPantry.VirtualConsole.Testing;\n using FluentAssertions;\n+using Microsoft.Extensions.Logging;\n using Moq;\n+using Spectre.Console;\n using Spectre.Console.Testing;\n using System.IO.Abstractions.TestingHelpers;\n+using System.Net;\n+using IHttpClientFactory = BitPantry.CommandLine.Remote.SignalR.Client.IHttpClientFactory;\n \n namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n {\n@@ -26,16 +32,9 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n         [TestInitialize]\n         public void Setup()\n         {\n-            _proxyMock = new Mock<IServerProxy>();\n+            _proxyMock = TestServerProxyFactory.CreateConnected();\n             _console = new TestConsole();\n             _fileSystem = new MockFileSystem();\n-\n-            _proxyMock.Setup(p => p.ConnectionState).Returns(ServerProxyConnectionState.Connected);\n-            _proxyMock.Setup(p => p.Server).Returns(new ServerCapabilities(\n-                new Uri(\"https://localhost:5000\"),\n-                \"test-connection-id\",\n-                new List<CommandInfo>(),\n-                100 * 1024 * 1024)); // 100MB default\n         }\n \n         #region Connection Verification Tests (CV-001, UX-004, EH-001)\n@@ -144,35 +143,18 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n \n         /// <summary>\n         /// Implements: CV-003, T021\n-        /// Literal path (no glob characters) triggers direct lookup\n-        /// </summary>\n-        [TestMethod]\n-        public void IsLiteralPath_NoGlobCharacters_ReturnsTrue()\n-        {\n-            // Arrange\n-            var command = CreateCommand();\n-\n-            // Act & Assert\n-            command.IsLiteralPath(\"config.json\").Should().BeTrue();\n-            command.IsLiteralPath(\"folder/file.txt\").Should().BeTrue();\n-            command.IsLiteralPath(\"/absolute/path.log\").Should().BeTrue();\n-        }\n-\n-        /// <summary>\n-        /// Implements: CV-002\n-        /// Path with glob characters detected for pattern expansion\n+        /// IsLiteralPath delegates to GlobPatternHelper.ContainsGlobCharacters.\n+        /// Detailed pattern tests are in GlobPatternHelperTests.\n         /// </summary>\n         [TestMethod]\n-        public void IsLiteralPath_WithGlobCharacters_ReturnsFalse()\n+        public void IsLiteralPath_DelegatesToGlobPatternHelper()\n         {\n             // Arrange\n             var command = CreateCommand();\n \n-            // Act & Assert\n-            command.IsLiteralPath(\"*.txt\").Should().BeFalse();\n-            command.IsLiteralPath(\"data?.json\").Should().BeFalse();\n-            command.IsLiteralPath(\"logs/**/*.log\").Should().BeFalse();\n-            // Note: [abc].txt character class syntax is not currently supported by ContainsGlobCharacters\n+            // Act & Assert - just verify delegation works\n+            command.IsLiteralPath(\"config.json\").Should().BeTrue(\"literal path has no globs\");\n+            command.IsLiteralPath(\"*.txt\").Should().BeFalse(\"* is a glob character\");\n         }\n \n         #endregion\n@@ -209,6 +191,7 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n         /// Implements: EH-011, T066\n         /// When: Empty source pattern provided\n         /// Then: Display error with helpful message suggesting valid format\n+        /// Note: GlobPatternHelper.ValidatePattern is tested in GlobPatternHelperTests.\n         /// </summary>\n         [TestMethod]\n         public async Task Execute_EmptySource_DisplaysHelpfulError()\n@@ -246,63 +229,230 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n             _console.Output.Should().Contain(\"Invalid\", \"should indicate pattern is invalid\");\n         }\n \n+        #endregion\n+\n+        #region Glob Pattern Expansion Tests (UX-006, T037)\n+\n         /// <summary>\n-        /// Implements: EH-011\n-        /// Validates that GlobPatternHelper.ValidatePattern rejects empty patterns.\n+        /// Implements: UX-006, T037\n+        /// When: User runs download with glob pattern \"*.txt\" and 3 files match\n+        /// Then: All 3 matching files are returned by ExpandSourcePattern\n         /// </summary>\n         [TestMethod]\n-        public void ValidatePattern_EmptyString_ReturnsError()\n+        public async Task ExpandSourcePattern_GlobMatchesMultipleFiles_ReturnsAllMatches()\n         {\n+            // Arrange\n+            var serverFiles = new[]\n+            {\n+                new FileInfoEntry(\"file1.txt\", 100, DateTime.Now),\n+                new FileInfoEntry(\"file2.txt\", 200, DateTime.Now),\n+                new FileInfoEntry(\"file3.txt\", 300, DateTime.Now)\n+            };\n+\n+            var response = new EnumerateFilesResponse(Guid.NewGuid().ToString(), serverFiles);\n+            _proxyMock\n+                .Setup(p => p.SendRpcRequest<EnumerateFilesResponse>(\n+                    It.IsAny<EnumerateFilesRequest>(), \n+                    It.IsAny<CancellationToken>()))\n+                .ReturnsAsync(response);\n+\n+            var fileTransferService = CreateFileTransferService();\n+            var command = CreateCommand(fileTransferService);\n+            command.Source = \"*.txt\";\n+            command.Destination = @\"C:\\backup\\\";\n+\n             // Act\n-            var result = GlobPatternHelper.ValidatePattern(\"\");\n+            var result = await command.ExpandSourcePattern(\"*.txt\", CancellationToken.None);\n \n             // Assert\n-            result.IsValid.Should().BeFalse(\"empty pattern should be invalid\");\n-            result.ErrorMessage.Should().NotBeNullOrEmpty(\"should provide error message\");\n-            result.SuggestedFormat.Should().NotBeNullOrEmpty(\"should suggest valid format\");\n+            result.Should().HaveCount(3, \"glob pattern should match all 3 txt files\");\n+            result.Select(f => _fileSystem.Path.GetFileName(f.Path))\n+                .Should().Contain(new[] { \"file1.txt\", \"file2.txt\", \"file3.txt\" });\n         }\n \n         /// <summary>\n-        /// Implements: EH-011\n-        /// Validates that GlobPatternHelper.ValidatePattern rejects whitespace-only patterns.\n+        /// Implements: UX-007, T038\n+        /// When: User runs download with directory-scoped glob pattern \"logs/*.log\"\n+        /// Then: Only files in the logs directory matching *.log are returned\n         /// </summary>\n         [TestMethod]\n-        public void ValidatePattern_WhitespaceOnly_ReturnsError()\n+        public async Task ExpandSourcePattern_DirectoryScopedGlob_ReturnsOnlyFilesInDirectory()\n         {\n+            // Arrange - Server returns files from the logs directory\n+            var serverFiles = new[]\n+            {\n+                new FileInfoEntry(\"app.log\", 100, DateTime.Now),\n+                new FileInfoEntry(\"error.log\", 200, DateTime.Now)\n+            };\n+\n+            var response = new EnumerateFilesResponse(Guid.NewGuid().ToString(), serverFiles);\n+            _proxyMock\n+                .Setup(p => p.SendRpcRequest<EnumerateFilesResponse>(\n+                    It.Is<EnumerateFilesRequest>(r => r.Path == \"logs\" && r.SearchPattern == \"*.log\"),\n+                    It.IsAny<CancellationToken>()))\n+                .ReturnsAsync(response);\n+\n+            var fileTransferService = CreateFileTransferService();\n+            var command = CreateCommand(fileTransferService);\n+            command.Source = \"logs/*.log\";\n+            command.Destination = @\"C:\\archive\\\";\n+\n             // Act\n-            var result = GlobPatternHelper.ValidatePattern(\"   \");\n+            var result = await command.ExpandSourcePattern(\"logs/*.log\", CancellationToken.None);\n \n             // Assert\n-            result.IsValid.Should().BeFalse(\"whitespace-only pattern should be invalid\");\n-            result.ErrorMessage.Should().Contain(\"empty\", \"should indicate pattern is empty/whitespace\");\n+            result.Should().HaveCount(2, \"should return only files from logs directory\");\n+            result.Select(f => f.Path).Should().AllSatisfy(p => p.Should().StartWith(\"logs/\"));\n+            result.Select(f => _fileSystem.Path.GetFileName(f.Path))\n+                .Should().Contain(new[] { \"app.log\", \"error.log\" });\n+\n+            // Verify the request was made with the correct directory\n+            _proxyMock.Verify(p => p.SendRpcRequest<EnumerateFilesResponse>(\n+                It.Is<EnumerateFilesRequest>(r => r.Path == \"logs\"),\n+                It.IsAny<CancellationToken>()), Times.Once);\n         }\n \n         /// <summary>\n-        /// Implements: EH-011\n-        /// Valid patterns pass validation.\n+        /// Implements: UX-009, T040\n+        /// When: User runs download with single-char wildcard pattern \"file?.txt\"\n+        /// Then: Only files matching exactly one character after \"file\" are returned\n+        /// Note: file10.txt does NOT match because \"10\" is two characters\n         /// </summary>\n         [TestMethod]\n-        public void ValidatePattern_ValidPatterns_ReturnsSuccess()\n+        public async Task ExpandSourcePattern_SingleCharWildcard_MatchesExactlyOneCharacter()\n         {\n-            // Arrange\n-            var validPatterns = new[]\n+            // Arrange - Server returns all files, but only file1.txt and file2.txt match \"file?.txt\"\n+            // file10.txt has TWO characters after \"file\", so it should be filtered out\n+            var serverFiles = new[]\n             {\n-                \"file.txt\",\n-                \"*.txt\",\n-                \"folder/*.log\",\n-                \"**/*.json\",\n-                \"data?.csv\",\n-                \"logs/2024/*.log\"\n+                new FileInfoEntry(\"file1.txt\", 100, DateTime.Now),\n+                new FileInfoEntry(\"file2.txt\", 200, DateTime.Now),\n+                new FileInfoEntry(\"file10.txt\", 300, DateTime.Now)  // Should NOT match - \"10\" is 2 chars\n             };\n \n-            foreach (var pattern in validPatterns)\n+            var response = new EnumerateFilesResponse(Guid.NewGuid().ToString(), serverFiles);\n+            _proxyMock\n+                .Setup(p => p.SendRpcRequest<EnumerateFilesResponse>(\n+                    It.IsAny<EnumerateFilesRequest>(),\n+                    It.IsAny<CancellationToken>()))\n+                .ReturnsAsync(response);\n+\n+            var fileTransferService = CreateFileTransferService();\n+            var command = CreateCommand(fileTransferService);\n+            command.Source = \"file?.txt\";\n+            command.Destination = @\"C:\\downloads\\\";\n+\n+            // Act\n+            var result = await command.ExpandSourcePattern(\"file?.txt\", CancellationToken.None);\n+\n+            // Assert\n+            result.Should().HaveCount(2, \"? wildcard matches exactly ONE character, not two\");\n+            result.Select(f => _fileSystem.Path.GetFileName(f.Path))\n+                .Should().Contain(new[] { \"file1.txt\", \"file2.txt\" });\n+            result.Select(f => _fileSystem.Path.GetFileName(f.Path))\n+                .Should().NotContain(\"file10.txt\", \"file10.txt has two chars after 'file', not one\");\n+        }\n+\n+        /// <summary>\n+        /// Implements: UX-010, T041\n+        /// When: User runs download with pattern \"*.xyz\" that matches no files\n+        /// Then: Warning message \"No files matched pattern: *.xyz\" is displayed in yellow\n+        /// </summary>\n+        [TestMethod]\n+        public async Task Execute_NoMatchingFiles_DisplaysYellowWarning()\n+        {\n+            // Arrange - Use VirtualConsoleAnsiAdapter to verify color\n+            var virtualConsole = new BitPantry.VirtualConsole.VirtualConsole(80, 10);\n+            var console = new VirtualConsoleAnsiAdapter(virtualConsole);\n+            \n+            var response = new EnumerateFilesResponse(Guid.NewGuid().ToString(), Array.Empty<FileInfoEntry>());\n+            _proxyMock\n+                .Setup(p => p.SendRpcRequest<EnumerateFilesResponse>(\n+                    It.IsAny<EnumerateFilesRequest>(),\n+                    It.IsAny<CancellationToken>()))\n+                .ReturnsAsync(response);\n+            _proxyMock.Setup(p => p.ConnectionState).Returns(ServerProxyConnectionState.Connected);\n+\n+            var fileTransferService = CreateFileTransferService();\n+            var command = new DownloadCommand(\n+                _proxyMock.Object,\n+                fileTransferService,\n+                console,\n+                _fileSystem);\n+            command.Source = \"*.xyz\";\n+            command.Destination = @\"C:\\downloads\\\";\n+\n+            // Act\n+            await command.Execute(CreateContext());\n+\n+            // Assert - Should display warning message with pattern in yellow\n+            var screenContent = console.GetScreenContent();\n+            screenContent.Should().Contain(\"No files matched pattern\");\n+            screenContent.Should().Contain(\"*.xyz\");\n+            \n+            // Verify the \"No files matched pattern\" text is rendered in yellow\n+            // Spectre.Console may use RGB or 256-color mode, so check for yellow-ish color\n+            var row = virtualConsole.GetRow(0);\n+            var cells = row.GetCells().ToList();\n+            // Find the 'N' in \"No files matched\" and verify it has a yellow-ish color\n+            var nCell = cells.FirstOrDefault(c => c.Character == 'N');\n+            nCell.Should().NotBeNull(\"should find 'N' character\");\n+            \n+            // Check for yellow in any color format (ConsoleColor, 256, or RGB)\n+            var style = nCell!.Style;\n+            var isYellow = style.ForegroundColor == System.ConsoleColor.DarkYellow ||\n+                           style.ForegroundColor == System.ConsoleColor.Yellow ||\n+                           style.Foreground256 == 11 || // bright yellow\n+                           style.Foreground256 == 3 ||  // dark yellow\n+                           (style.ForegroundRgb.HasValue && \n+                            style.ForegroundRgb.Value.R > 200 && \n+                            style.ForegroundRgb.Value.G > 200 && \n+                            style.ForegroundRgb.Value.B < 100); // yellowish RGB\n+            \n+            isYellow.Should().BeTrue(\"warning text should be displayed in yellow (got FG={0}, 256={1}, RGB={2})\",\n+                style.ForegroundColor, style.Foreground256, style.ForegroundRgb);\n+        }\n+\n+        /// <summary>\n+        /// Implements: UX-011, T042\n+        /// When: Pattern uses ** for recursive search\n+        /// Then: Files from all subdirectories are included in results\n+        /// </summary>\n+        [TestMethod]\n+        public async Task ExpandSourcePattern_RecursiveGlob_IncludesSubdirectories()\n+        {\n+            // Arrange - Server returns files from multiple levels\n+            var serverFiles = new[]\n             {\n-                // Act\n-                var result = GlobPatternHelper.ValidatePattern(pattern);\n+                new FileInfoEntry(\"root.log\", 100, DateTime.Now),\n+                new FileInfoEntry(\"sub1/app.log\", 200, DateTime.Now),\n+                new FileInfoEntry(\"sub1/sub2/deep.log\", 300, DateTime.Now)\n+            };\n+\n+            var response = new EnumerateFilesResponse(Guid.NewGuid().ToString(), serverFiles);\n+            _proxyMock\n+                .Setup(p => p.SendRpcRequest<EnumerateFilesResponse>(\n+                    It.Is<EnumerateFilesRequest>(r => r.SearchOption == \"AllDirectories\"),\n+                    It.IsAny<CancellationToken>()))\n+                .ReturnsAsync(response);\n+\n+            var fileTransferService = CreateFileTransferService();\n+            var command = CreateCommand(fileTransferService);\n+            command.Source = \"**/*.log\";\n+            command.Destination = @\"C:\\logs\\\";\n+\n+            // Act\n+            var result = await command.ExpandSourcePattern(\"**/*.log\", CancellationToken.None);\n+\n+            // Assert - Should include files from all levels\n+            result.Should().HaveCount(3, \"recursive pattern should match files in all subdirectories\");\n+            result.Select(f => _fileSystem.Path.GetFileName(f.Path))\n+                .Should().Contain(new[] { \"root.log\", \"app.log\", \"deep.log\" });\n \n-                // Assert\n-                result.IsValid.Should().BeTrue($\"pattern '{pattern}' should be valid\");\n-            }\n+            // Verify recursive search option was set in request\n+            _proxyMock.Verify(p => p.SendRpcRequest<EnumerateFilesResponse>(\n+                It.Is<EnumerateFilesRequest>(r => r.SearchOption == \"AllDirectories\"),\n+                It.IsAny<CancellationToken>()), Times.Once);\n         }\n \n         #endregion\n@@ -408,6 +558,85 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n             collisions.Should().Contain(c => c.FileName == \"data.json\" && c.Paths.Count == 2);\n         }\n \n+        /// <summary>\n+        /// Implements: UX-027, UX-029, T043, T045\n+        /// When: Glob matches files with same name in different directories\n+        /// Then: Error lists all conflicting filenames AND all conflicting paths\n+        /// </summary>\n+        [TestMethod]\n+        public async Task Execute_CollisionDetected_DisplaysErrorWithConflictingPaths()\n+        {\n+            // Arrange - Server returns files with same filename in different directories\n+            var serverFiles = new[]\n+            {\n+                new FileInfoEntry(\"dir1/config.json\", 100, DateTime.Now),\n+                new FileInfoEntry(\"dir2/config.json\", 200, DateTime.Now),\n+                new FileInfoEntry(\"dir1/unique.txt\", 50, DateTime.Now)\n+            };\n+\n+            var response = new EnumerateFilesResponse(Guid.NewGuid().ToString(), serverFiles);\n+            _proxyMock\n+                .Setup(p => p.SendRpcRequest<EnumerateFilesResponse>(\n+                    It.IsAny<EnumerateFilesRequest>(),\n+                    It.IsAny<CancellationToken>()))\n+                .ReturnsAsync(response);\n+            _proxyMock.Setup(p => p.ConnectionState).Returns(ServerProxyConnectionState.Connected);\n+\n+            var fileTransferService = CreateFileTransferService();\n+            var command = CreateCommand(fileTransferService);\n+            command.Source = \"**/*\";\n+            command.Destination = @\"C:\\downloads\\\";\n+\n+            // Act\n+            await command.Execute(CreateContext());\n+\n+            // Assert - Should display error with conflicting filenames\n+            _console.Output.Should().Contain(\"collision\", \"should indicate filename collision error\");\n+            _console.Output.Should().Contain(\"config.json\", \"should list the colliding filename\");\n+            _console.Output.Should().Contain(\"dir1\", \"should list the first conflicting path\");\n+            _console.Output.Should().Contain(\"dir2\", \"should list the second conflicting path\");\n+        }\n+\n+        /// <summary>\n+        /// Implements: UX-028, T044\n+        /// When: Collision detected in matched files\n+        /// Then: No files are downloaded (early abort before any download)\n+        /// </summary>\n+        [TestMethod]\n+        public async Task Execute_CollisionDetected_NoFilesDownloaded()\n+        {\n+            // Arrange - Server returns files with same filename in different directories\n+            var serverFiles = new[]\n+            {\n+                new FileInfoEntry(\"dir1/config.json\", 100, DateTime.Now),\n+                new FileInfoEntry(\"dir2/config.json\", 200, DateTime.Now)\n+            };\n+\n+            var response = new EnumerateFilesResponse(Guid.NewGuid().ToString(), serverFiles);\n+            _proxyMock\n+                .Setup(p => p.SendRpcRequest<EnumerateFilesResponse>(\n+                    It.IsAny<EnumerateFilesRequest>(),\n+                    It.IsAny<CancellationToken>()))\n+                .ReturnsAsync(response);\n+            _proxyMock.Setup(p => p.ConnectionState).Returns(ServerProxyConnectionState.Connected);\n+\n+            var fileTransferService = CreateFileTransferService();\n+            var command = CreateCommand(fileTransferService);\n+            command.Source = \"**/*\";\n+            command.Destination = @\"C:\\downloads\\\";\n+\n+            // Act\n+            await command.Execute(CreateContext());\n+\n+            // Assert - No download should have been attempted\n+            // When collisions are detected, the command returns early without downloading\n+            // We verify by checking that an error was displayed (which causes early exit)\n+            _console.Output.Should().Contain(\"collision\", \"should display collision error\");\n+            \n+            // Verify no success message was displayed (no files were downloaded)\n+            _console.Output.Should().NotContain(\"Downloaded\", \"no files should have been downloaded\");\n+        }\n+\n         #endregion\n \n         #region Helper Methods\n@@ -421,6 +650,11 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n                 _fileSystem);\n         }\n \n+        private FileTransferService CreateFileTransferService()\n+        {\n+            return TestFileTransferServiceFactory.Create(_proxyMock);\n+        }\n+\n         private CommandExecutionContext CreateContext()\n         {\n             return new CommandExecutionContext();\ndiff --git a/BitPantry.CommandLine.Tests.Remote.SignalR/ClientTests/FileTransferServiceAuthTests.cs b/BitPantry.CommandLine.Tests.Remote.SignalR/ClientTests/FileTransferServiceAuthTests.cs\nindex 280611d..4f93e1e 100644\n--- a/BitPantry.CommandLine.Tests.Remote.SignalR/ClientTests/FileTransferServiceAuthTests.cs\n+++ b/BitPantry.CommandLine.Tests.Remote.SignalR/ClientTests/FileTransferServiceAuthTests.cs\n@@ -19,43 +19,23 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n     [TestClass]\n     public class FileTransferServiceAuthTests\n     {\n-        private Mock<ILogger<FileTransferService>> _loggerMock;\n         private Mock<IServerProxy> _proxyMock;\n-        private Mock<IHttpClientFactory> _httpClientFactoryMock;\n-        private AccessTokenManager _accessTokenManager;\n-        private Mock<ILogger<FileUploadProgressUpdateFunctionRegistry>> _registryLoggerMock;\n-        private FileUploadProgressUpdateFunctionRegistry _uploadRegistry;\n-        private Mock<ILogger<FileDownloadProgressUpdateFunctionRegistry>> _downloadRegistryLoggerMock;\n-        private FileDownloadProgressUpdateFunctionRegistry _downloadRegistry;\n+        private FileTransferServiceTestContext _context;\n         private Mock<HttpMessageHandler> _httpMessageHandlerMock;\n-        private HttpClient _httpClient;\n+        private AccessTokenManager _accessTokenManager;\n         private List<HttpRequestMessage> _capturedRequests;\n \n         [TestInitialize]\n         public void Setup()\n         {\n-            _loggerMock = new Mock<ILogger<FileTransferService>>();\n-            _proxyMock = new Mock<IServerProxy>();\n-            _httpClientFactoryMock = new Mock<IHttpClientFactory>();\n-            _registryLoggerMock = new Mock<ILogger<FileUploadProgressUpdateFunctionRegistry>>();\n-            _uploadRegistry = new FileUploadProgressUpdateFunctionRegistry(_registryLoggerMock.Object);\n-            _downloadRegistryLoggerMock = new Mock<ILogger<FileDownloadProgressUpdateFunctionRegistry>>();\n-            _downloadRegistry = new FileDownloadProgressUpdateFunctionRegistry(_downloadRegistryLoggerMock.Object);\n+            _proxyMock = TestServerProxyFactory.CreateConnected();\n             _capturedRequests = new List<HttpRequestMessage>();\n \n-            // Setup proxy mock\n-            _proxyMock.Setup(p => p.ConnectionState).Returns(ServerProxyConnectionState.Connected);\n-            _proxyMock.Setup(p => p.Server).Returns(new ServerCapabilities(\n-                new Uri(\"https://localhost:5000\"),\n-                \"test-connection-id\",\n-                new List<CommandInfo>(),\n-                100 * 1024 * 1024));\n-\n-            // Create access token manager with a valid test token\n-            _accessTokenManager = TestAccessTokenManager.Create(new HttpResponseMessage(HttpStatusCode.Unauthorized));\n+            _context = TestFileTransferServiceFactory.CreateWithContext(_proxyMock);\n+            _httpMessageHandlerMock = _context.HttpMessageHandlerMock;\n+            _accessTokenManager = _context.AccessTokenManager;\n \n             // Setup HTTP handler mock to capture requests\n-            _httpMessageHandlerMock = new Mock<HttpMessageHandler>();\n             _httpMessageHandlerMock\n                 .Protected()\n                 .Setup<Task<HttpResponseMessage>>(\n@@ -71,9 +51,6 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n                     });\n                     return new HttpResponseMessage(HttpStatusCode.OK);\n                 });\n-\n-            _httpClient = new HttpClient(_httpMessageHandlerMock.Object);\n-            _httpClientFactoryMock.Setup(f => f.CreateClient()).Returns(_httpClient);\n         }\n \n         /// <summary>\n@@ -84,39 +61,24 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n         public async Task UploadFile_SendsAuthorizationBearerHeader()\n         {\n             // Arrange\n-            var tempFile = Path.GetTempFileName();\n-            File.WriteAllText(tempFile, \"test content\");\n+            using var tempFile = new TempFileScope(\"test content\");\n \n             // Set a test token first\n-            var testToken = TestJwtTokenService.GenerateAccessToken();\n-            await _accessTokenManager.SetAccessToken(testToken, \"https://localhost:5000\");\n+            var testToken = await _context.SetupAuthenticatedTokenAsync();\n \n-            var service = new FileTransferService(\n-                _loggerMock.Object,\n-                _proxyMock.Object,\n-                _httpClientFactoryMock.Object,\n-                _accessTokenManager,\n-                _uploadRegistry,\n-                _downloadRegistry);\n+            var service = _context.Service;\n \n+            // Act\n+            // Note: This will be cancelled after 1 second because we don't have\n+            // a real server to respond with progress updates. We just need to capture the request.\n+            using var cts = new CancellationTokenSource(TimeSpan.FromMilliseconds(100));\n             try\n             {\n-                // Act\n-                // Note: This will be cancelled after 1 second because we don't have\n-                // a real server to respond with progress updates. We just need to capture the request.\n-                using var cts = new CancellationTokenSource(TimeSpan.FromMilliseconds(100));\n-                try\n-                {\n-                    await service.UploadFile(tempFile, \"test.txt\", null, cts.Token);\n-                }\n-                catch (OperationCanceledException)\n-                {\n-                    // Expected - test is designed to cancel after capturing the request\n-                }\n+                await service.UploadFile(tempFile.Path, \"test.txt\", null, cts.Token);\n             }\n-            finally\n+            catch (OperationCanceledException)\n             {\n-                File.Delete(tempFile);\n+                // Expected - test is designed to cancel after capturing the request\n             }\n \n             // Assert\n@@ -136,37 +98,22 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n         public async Task UploadFile_DoesNotIncludeTokenInQueryString()\n         {\n             // Arrange\n-            var tempFile = Path.GetTempFileName();\n-            File.WriteAllText(tempFile, \"test content\");\n+            using var tempFile = new TempFileScope(\"test content\");\n \n             // Set a test token first\n-            var testToken = TestJwtTokenService.GenerateAccessToken();\n-            await _accessTokenManager.SetAccessToken(testToken, \"https://localhost:5000\");\n+            var testToken = await _context.SetupAuthenticatedTokenAsync();\n \n-            var service = new FileTransferService(\n-                _loggerMock.Object,\n-                _proxyMock.Object,\n-                _httpClientFactoryMock.Object,\n-                _accessTokenManager,\n-                _uploadRegistry,\n-                _downloadRegistry);\n+            var service = _context.Service;\n \n+            // Act\n+            using var cts = new CancellationTokenSource(TimeSpan.FromMilliseconds(100));\n             try\n             {\n-                // Act\n-                using var cts = new CancellationTokenSource(TimeSpan.FromMilliseconds(100));\n-                try\n-                {\n-                    await service.UploadFile(tempFile, \"test.txt\", null, cts.Token);\n-                }\n-                catch (OperationCanceledException)\n-                {\n-                    // Expected - test is designed to cancel after capturing the request\n-                }\n+                await service.UploadFile(tempFile.Path, \"test.txt\", null, cts.Token);\n             }\n-            finally\n+            catch (OperationCanceledException)\n             {\n-                File.Delete(tempFile);\n+                // Expected - test is designed to cancel after capturing the request\n             }\n \n             // Assert\n@@ -187,8 +134,7 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n         public async Task DownloadFile_SendsAuthorizationBearerHeader()\n         {\n             // Arrange\n-            var testToken = TestJwtTokenService.GenerateAccessToken();\n-            await _accessTokenManager.SetAccessToken(testToken, \"https://localhost:5000\");\n+            var testToken = await _context.SetupAuthenticatedTokenAsync();\n \n             // Reset captured requests\n             _capturedRequests.Clear();\n@@ -218,33 +164,19 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n                     return response;\n                 });\n \n-            var service = new FileTransferService(\n-                _loggerMock.Object,\n-                _proxyMock.Object,\n-                _httpClientFactoryMock.Object,\n-                _accessTokenManager,\n-                _uploadRegistry,\n-                _downloadRegistry);\n+            var service = _context.Service;\n \n-            var outputPath = Path.GetTempFileName();\n+            using var tempFile = new TempFileScope();\n \n-            try\n-            {\n-                // Act\n-                await service.DownloadFile(\"test-file.txt\", outputPath, CancellationToken.None);\n+            // Act\n+            await service.DownloadFile(\"test-file.txt\", tempFile.Path, CancellationToken.None);\n \n-                // Assert\n-                _capturedRequests.Should().HaveCount(1);\n-                var request = _capturedRequests[0];\n-                request.Headers.Authorization.Should().NotBeNull();\n-                request.Headers.Authorization.Scheme.Should().Be(\"Bearer\");\n-                request.Headers.Authorization.Parameter.Should().Be(testToken.Token);\n-            }\n-            finally\n-            {\n-                if (File.Exists(outputPath))\n-                    File.Delete(outputPath);\n-            }\n+            // Assert\n+            _capturedRequests.Should().HaveCount(1);\n+            var request = _capturedRequests[0];\n+            request.Headers.Authorization.Should().NotBeNull();\n+            request.Headers.Authorization.Scheme.Should().Be(\"Bearer\");\n+            request.Headers.Authorization.Parameter.Should().Be(testToken.Token);\n         }\n \n         /// <summary>\n@@ -255,8 +187,7 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n         public async Task DownloadFile_DoesNotIncludeTokenInQueryString()\n         {\n             // Arrange\n-            var testToken = TestJwtTokenService.GenerateAccessToken();\n-            await _accessTokenManager.SetAccessToken(testToken, \"https://localhost:5000\");\n+            var testToken = await _context.SetupAuthenticatedTokenAsync();\n \n             // Reset captured requests\n             _capturedRequests.Clear();\n@@ -283,33 +214,19 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n                     return response;\n                 });\n \n-            var service = new FileTransferService(\n-                _loggerMock.Object,\n-                _proxyMock.Object,\n-                _httpClientFactoryMock.Object,\n-                _accessTokenManager,\n-                _uploadRegistry,\n-                _downloadRegistry);\n+            var service = _context.Service;\n \n-            var outputPath = Path.GetTempFileName();\n+            using var tempFile = new TempFileScope();\n \n-            try\n-            {\n-                // Act\n-                await service.DownloadFile(\"test-file.txt\", outputPath, CancellationToken.None);\n+            // Act\n+            await service.DownloadFile(\"test-file.txt\", tempFile.Path, CancellationToken.None);\n \n-                // Assert - token should NOT be in query string\n-                _capturedRequests.Should().HaveCount(1);\n-                var request = _capturedRequests[0];\n-                var queryString = request.RequestUri.Query;\n-                queryString.Should().NotContain(\"token\");\n-                queryString.Should().NotContain(testToken.Token, \"Token value should not appear in URL\");\n-            }\n-            finally\n-            {\n-                if (File.Exists(outputPath))\n-                    File.Delete(outputPath);\n-            }\n+            // Assert - token should NOT be in query string\n+            _capturedRequests.Should().HaveCount(1);\n+            var request = _capturedRequests[0];\n+            var queryString = request.RequestUri.Query;\n+            queryString.Should().NotContain(\"token\");\n+            queryString.Should().NotContain(testToken.Token, \"Token value should not appear in URL\");\n         }\n     }\n }\ndiff --git a/BitPantry.CommandLine.Tests.Remote.SignalR/ClientTests/FileTransferServiceDownloadTests.cs b/BitPantry.CommandLine.Tests.Remote.SignalR/ClientTests/FileTransferServiceDownloadTests.cs\nindex 450449b..4464496 100644\n--- a/BitPantry.CommandLine.Tests.Remote.SignalR/ClientTests/FileTransferServiceDownloadTests.cs\n+++ b/BitPantry.CommandLine.Tests.Remote.SignalR/ClientTests/FileTransferServiceDownloadTests.cs\n@@ -20,49 +20,21 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n     [TestClass]\n     public class FileTransferServiceDownloadTests\n     {\n-        private Mock<ILogger<FileTransferService>> _loggerMock;\n         private Mock<IServerProxy> _proxyMock;\n-        private Mock<IHttpClientFactory> _httpClientFactoryMock;\n-        private AccessTokenManager _accessTokenManager;\n-        private Mock<ILogger<FileUploadProgressUpdateFunctionRegistry>> _uploadRegistryLoggerMock;\n-        private FileUploadProgressUpdateFunctionRegistry _uploadRegistry;\n-        private Mock<ILogger<FileDownloadProgressUpdateFunctionRegistry>> _downloadRegistryLoggerMock;\n-        private FileDownloadProgressUpdateFunctionRegistry _downloadRegistry;\n+        private FileTransferServiceTestContext _context;\n         private Mock<HttpMessageHandler> _httpMessageHandlerMock;\n-        private HttpClient _httpClient;\n+        private AccessTokenManager _accessTokenManager;\n         private FileTransferService _service;\n \n         [TestInitialize]\n         public void Setup()\n         {\n-            _loggerMock = new Mock<ILogger<FileTransferService>>();\n-            _proxyMock = new Mock<IServerProxy>();\n-            _httpClientFactoryMock = new Mock<IHttpClientFactory>();\n-            _uploadRegistryLoggerMock = new Mock<ILogger<FileUploadProgressUpdateFunctionRegistry>>();\n-            _uploadRegistry = new FileUploadProgressUpdateFunctionRegistry(_uploadRegistryLoggerMock.Object);\n-            _downloadRegistryLoggerMock = new Mock<ILogger<FileDownloadProgressUpdateFunctionRegistry>>();\n-            _downloadRegistry = new FileDownloadProgressUpdateFunctionRegistry(_downloadRegistryLoggerMock.Object);\n-\n-            _proxyMock.Setup(p => p.ConnectionState).Returns(ServerProxyConnectionState.Connected);\n-            _proxyMock.Setup(p => p.Server).Returns(new ServerCapabilities(\n-                new Uri(\"https://localhost:5000\"),\n-                \"test-connection-id\",\n-                new List<CommandInfo>(),\n-                100 * 1024 * 1024));\n-\n-            _accessTokenManager = TestAccessTokenManager.Create(new HttpResponseMessage(HttpStatusCode.Unauthorized));\n-\n-            _httpMessageHandlerMock = new Mock<HttpMessageHandler>();\n-            _httpClient = new HttpClient(_httpMessageHandlerMock.Object);\n-            _httpClientFactoryMock.Setup(f => f.CreateClient()).Returns(_httpClient);\n-\n-            _service = new FileTransferService(\n-                _loggerMock.Object,\n-                _proxyMock.Object,\n-                _httpClientFactoryMock.Object,\n-                _accessTokenManager,\n-                _uploadRegistry,\n-                _downloadRegistry);\n+            _proxyMock = TestServerProxyFactory.CreateConnected();\n+\n+            _context = TestFileTransferServiceFactory.CreateWithContext(_proxyMock);\n+            _httpMessageHandlerMock = _context.HttpMessageHandlerMock;\n+            _accessTokenManager = _context.AccessTokenManager;\n+            _service = _context.Service;\n         }\n \n         /// <summary>\n@@ -80,8 +52,7 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n             using var sha256 = SHA256.Create();\n             var checksum = Convert.ToHexString(sha256.ComputeHash(contentBytes));\n \n-            var testToken = TestJwtTokenService.GenerateAccessToken();\n-            await _accessTokenManager.SetAccessToken(testToken, \"https://localhost:5000\");\n+            await _context.SetupAuthenticatedTokenAsync();\n \n             _httpMessageHandlerMock\n                 .Protected()\n@@ -101,22 +72,14 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n                     return response;\n                 });\n \n-            var outputPath = Path.GetTempFileName();\n+            using var tempFile = new TempFileScope();\n \n-            try\n-            {\n-                // Act\n-                await _service.DownloadFile(\"test-file.txt\", outputPath, CancellationToken.None);\n+            // Act\n+            await _service.DownloadFile(\"test-file.txt\", tempFile.Path, CancellationToken.None);\n \n-                // Assert\n-                File.Exists(outputPath).Should().BeTrue();\n-                File.ReadAllText(outputPath).Should().Be(expectedContent);\n-            }\n-            finally\n-            {\n-                if (File.Exists(outputPath))\n-                    File.Delete(outputPath);\n-            }\n+            // Assert\n+            tempFile.Exists.Should().BeTrue();\n+            tempFile.ReadAllText().Should().Be(expectedContent);\n         }\n \n         /// <summary>\n@@ -127,8 +90,7 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n         public async Task DownloadFile_FileNotFound_ThrowsFileNotFoundException()\n         {\n             // Arrange\n-            var testToken = TestJwtTokenService.GenerateAccessToken();\n-            await _accessTokenManager.SetAccessToken(testToken, \"https://localhost:5000\");\n+            await _context.SetupAuthenticatedTokenAsync();\n \n             _httpMessageHandlerMock\n                 .Protected()\n@@ -138,20 +100,12 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n                     ItExpr.IsAny<CancellationToken>())\n                 .ReturnsAsync(new HttpResponseMessage(HttpStatusCode.NotFound));\n \n-            var outputPath = Path.GetTempFileName();\n+            using var tempFile = new TempFileScope();\n \n-            try\n-            {\n-                // Act & Assert\n-                await _service.Invoking(s => s.DownloadFile(\"nonexistent.txt\", outputPath, CancellationToken.None))\n-                    .Should().ThrowAsync<FileNotFoundException>()\n-                    .WithMessage(\"*nonexistent.txt*\");\n-            }\n-            finally\n-            {\n-                if (File.Exists(outputPath))\n-                    File.Delete(outputPath);\n-            }\n+            // Act & Assert\n+            await _service.Invoking(s => s.DownloadFile(\"nonexistent.txt\", tempFile.Path, CancellationToken.None))\n+                .Should().ThrowAsync<FileNotFoundException>()\n+                .WithMessage(\"*nonexistent.txt*\");\n         }\n \n         /// <summary>\n@@ -165,8 +119,7 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n             var contentBytes = Encoding.UTF8.GetBytes(\"File content\");\n             var wrongChecksum = \"WRONGCHECKSUMVALUE123456789\";\n \n-            var testToken = TestJwtTokenService.GenerateAccessToken();\n-            await _accessTokenManager.SetAccessToken(testToken, \"https://localhost:5000\");\n+            await _context.SetupAuthenticatedTokenAsync();\n \n             _httpMessageHandlerMock\n                 .Protected()\n@@ -184,25 +137,16 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n                     return response;\n                 });\n \n-            var outputPath = Path.GetTempFileName();\n-            // Delete the temp file so we can verify partial file cleanup behavior\n-            File.Delete(outputPath);\n+            // Use WithoutFile() to verify partial file cleanup behavior\n+            using var tempFile = TempFileScope.WithoutFile();\n \n-            try\n-            {\n-                // Act & Assert\n-                await _service.Invoking(s => s.DownloadFile(\"test-file.txt\", outputPath, CancellationToken.None))\n-                    .Should().ThrowAsync<InvalidDataException>()\n-                    .WithMessage(\"*Checksum*\");\n+            // Act & Assert\n+            await _service.Invoking(s => s.DownloadFile(\"test-file.txt\", tempFile.Path, CancellationToken.None))\n+                .Should().ThrowAsync<InvalidDataException>()\n+                .WithMessage(\"*Checksum*\");\n \n-                // Verify partial file is deleted after checksum failure (CV-013 requirement)\n-                File.Exists(outputPath).Should().BeFalse(\"partial file should be deleted on checksum failure\");\n-            }\n-            finally\n-            {\n-                if (File.Exists(outputPath))\n-                    File.Delete(outputPath);\n-            }\n+            // Verify partial file is deleted after checksum failure (CV-013 requirement)\n+            tempFile.Exists.Should().BeFalse(\"partial file should be deleted on checksum failure\");\n         }\n \n         /// <summary>\n@@ -213,8 +157,7 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n         public async Task DownloadFile_Cancelled_ThrowsTaskCancelledException()\n         {\n             // Arrange\n-            var testToken = TestJwtTokenService.GenerateAccessToken();\n-            await _accessTokenManager.SetAccessToken(testToken, \"https://localhost:5000\");\n+            await _context.SetupAuthenticatedTokenAsync();\n \n             var cts = new CancellationTokenSource();\n             cts.Cancel(); // Cancel immediately\n@@ -227,19 +170,11 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n                     ItExpr.IsAny<CancellationToken>())\n                 .ThrowsAsync(new TaskCanceledException());\n \n-            var outputPath = Path.GetTempFileName();\n+            using var tempFile = new TempFileScope();\n \n-            try\n-            {\n-                // Act & Assert\n-                await _service.Invoking(s => s.DownloadFile(\"test-file.txt\", outputPath, cts.Token))\n-                    .Should().ThrowAsync<TaskCanceledException>();\n-            }\n-            finally\n-            {\n-                if (File.Exists(outputPath))\n-                    File.Delete(outputPath);\n-            }\n+            // Act & Assert\n+            await _service.Invoking(s => s.DownloadFile(\"test-file.txt\", tempFile.Path, cts.Token))\n+                .Should().ThrowAsync<TaskCanceledException>();\n         }\n \n         /// <summary>\n@@ -256,8 +191,7 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n             using var sha256 = SHA256.Create();\n             var checksum = Convert.ToHexString(sha256.ComputeHash(contentBytes));\n \n-            var testToken = TestJwtTokenService.GenerateAccessToken();\n-            await _accessTokenManager.SetAccessToken(testToken, \"https://localhost:5000\");\n+            var testToken = await _context.SetupAuthenticatedTokenAsync();\n \n             _httpMessageHandlerMock\n                 .Protected()\n@@ -283,24 +217,16 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n                     return response;\n                 });\n \n-            var outputPath = Path.GetTempFileName();\n+            using var tempFile = new TempFileScope();\n \n-            try\n-            {\n-                // Act\n-                await _service.DownloadFile(\"test-file.txt\", outputPath, CancellationToken.None);\n+            // Act\n+            await _service.DownloadFile(\"test-file.txt\", tempFile.Path, CancellationToken.None);\n \n-                // Assert\n-                capturedRequest.Should().NotBeNull();\n-                capturedRequest.Headers.Authorization.Should().NotBeNull();\n-                capturedRequest.Headers.Authorization.Scheme.Should().Be(\"Bearer\");\n-                capturedRequest.Headers.Authorization.Parameter.Should().Be(testToken.Token);\n-            }\n-            finally\n-            {\n-                if (File.Exists(outputPath))\n-                    File.Delete(outputPath);\n-            }\n+            // Assert\n+            capturedRequest.Should().NotBeNull();\n+            capturedRequest.Headers.Authorization.Should().NotBeNull();\n+            capturedRequest.Headers.Authorization.Scheme.Should().Be(\"Bearer\");\n+            capturedRequest.Headers.Authorization.Parameter.Should().Be(testToken.Token);\n         }\n \n         /// <summary>\n@@ -317,8 +243,7 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n             using var sha256 = SHA256.Create();\n             var checksum = Convert.ToHexString(sha256.ComputeHash(contentBytes));\n \n-            var testToken = TestJwtTokenService.GenerateAccessToken();\n-            await _accessTokenManager.SetAccessToken(testToken, \"https://localhost:5000\");\n+            var testToken = await _context.SetupAuthenticatedTokenAsync();\n \n             _httpMessageHandlerMock\n                 .Protected()\n@@ -338,23 +263,15 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n                     return response;\n                 });\n \n-            var outputPath = Path.GetTempFileName();\n+            using var tempFile = new TempFileScope();\n \n-            try\n-            {\n-                // Act\n-                await _service.DownloadFile(\"test-file.txt\", outputPath, CancellationToken.None);\n+            // Act\n+            await _service.DownloadFile(\"test-file.txt\", tempFile.Path, CancellationToken.None);\n \n-                // Assert - token should NOT be in query string\n-                capturedRequest.Should().NotBeNull();\n-                capturedRequest.RequestUri.Query.Should().NotContain(\"token\");\n-                capturedRequest.RequestUri.Query.Should().NotContain(testToken.Token);\n-            }\n-            finally\n-            {\n-                if (File.Exists(outputPath))\n-                    File.Delete(outputPath);\n-            }\n+            // Assert - token should NOT be in query string\n+            capturedRequest.Should().NotBeNull();\n+            capturedRequest.RequestUri.Query.Should().NotContain(\"token\");\n+            capturedRequest.RequestUri.Query.Should().NotContain(testToken.Token);\n         }\n \n         /// <summary>\n@@ -367,29 +284,15 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n             // Arrange\n             _proxyMock.Setup(p => p.ConnectionState).Returns(ServerProxyConnectionState.Disconnected);\n \n-            // Create a new service with the disconnected proxy\n-            var service = new FileTransferService(\n-                _loggerMock.Object,\n-                _proxyMock.Object,\n-                _httpClientFactoryMock.Object,\n-                _accessTokenManager,\n-                _uploadRegistry,\n-                _downloadRegistry);\n+            // Create a new service with the disconnected proxy using factory\n+            var service = TestFileTransferServiceFactory.Create(_proxyMock);\n \n-            var outputPath = Path.GetTempFileName();\n+            using var tempFile = new TempFileScope();\n \n-            try\n-            {\n-                // Act & Assert\n-                await service.Invoking(s => s.DownloadFile(\"test-file.txt\", outputPath, CancellationToken.None))\n-                    .Should().ThrowAsync<InvalidOperationException>()\n-                    .WithMessage(\"*disconnected*\");\n-            }\n-            finally\n-            {\n-                if (File.Exists(outputPath))\n-                    File.Delete(outputPath);\n-            }\n+            // Act & Assert\n+            await service.Invoking(s => s.DownloadFile(\"test-file.txt\", tempFile.Path, CancellationToken.None))\n+                .Should().ThrowAsync<InvalidOperationException>()\n+                .WithMessage(\"*disconnected*\");\n         }\n \n         /// <summary>\n@@ -406,8 +309,7 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n             using var sha256 = SHA256.Create();\n             var checksum = Convert.ToHexString(sha256.ComputeHash(contentBytes));\n \n-            var testToken = TestJwtTokenService.GenerateAccessToken();\n-            await _accessTokenManager.SetAccessToken(testToken, \"https://localhost:5000\");\n+            await _context.SetupAuthenticatedTokenAsync();\n \n             _httpMessageHandlerMock\n                 .Protected()\ndiff --git a/BitPantry.CommandLine.Tests.Remote.SignalR/ClientTests/GlobPatternHelperTests.cs b/BitPantry.CommandLine.Tests.Remote.SignalR/ClientTests/GlobPatternHelperTests.cs\nindex 18092d5..91fe938 100644\n--- a/BitPantry.CommandLine.Tests.Remote.SignalR/ClientTests/GlobPatternHelperTests.cs\n+++ b/BitPantry.CommandLine.Tests.Remote.SignalR/ClientTests/GlobPatternHelperTests.cs\n@@ -20,6 +20,57 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n             _fileSystem.Directory.SetCurrentDirectory(@\"C:\\testdir\");\n         }\n \n+        #region ValidatePattern Tests\n+\n+        [TestMethod]\n+        public void ValidatePattern_EmptyString_ReturnsError()\n+        {\n+            // Act\n+            var result = GlobPatternHelper.ValidatePattern(\"\");\n+\n+            // Assert\n+            result.IsValid.Should().BeFalse(\"empty pattern should be invalid\");\n+            result.ErrorMessage.Should().NotBeNullOrEmpty(\"should provide error message\");\n+            result.SuggestedFormat.Should().NotBeNullOrEmpty(\"should suggest valid format\");\n+        }\n+\n+        [TestMethod]\n+        public void ValidatePattern_WhitespaceOnly_ReturnsError()\n+        {\n+            // Act\n+            var result = GlobPatternHelper.ValidatePattern(\"   \");\n+\n+            // Assert\n+            result.IsValid.Should().BeFalse(\"whitespace-only pattern should be invalid\");\n+            result.ErrorMessage.Should().Contain(\"empty\", \"should indicate pattern is empty/whitespace\");\n+        }\n+\n+        [TestMethod]\n+        public void ValidatePattern_ValidPatterns_ReturnsSuccess()\n+        {\n+            // Arrange\n+            var validPatterns = new[]\n+            {\n+                \"file.txt\",\n+                \"*.txt\",\n+                \"folder/*.log\",\n+                \"**/*.json\",\n+                \"data?.csv\",\n+                \"logs/2024/*.log\"\n+            };\n+\n+            foreach (var pattern in validPatterns)\n+            {\n+                // Act\n+                var result = GlobPatternHelper.ValidatePattern(pattern);\n+\n+                // Assert\n+                result.IsValid.Should().BeTrue($\"pattern '{pattern}' should be valid\");\n+            }\n+        }\n+\n+        #endregion\n+\n         #region ContainsGlobCharacters Tests\n \n         [TestMethod]\n@@ -274,5 +325,243 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n         }\n \n         #endregion\n+\n+        #region ResolveDestinationPath Tests\n+\n+        [TestMethod]\n+        public void ResolveDestinationPath_DestinationEndsWithSlash_AppendsFilename()\n+        {\n+            // Arrange\n+            var destination = \"C:/downloads/\";\n+            var fileName = \"myfile.txt\";\n+\n+            // Act\n+            var result = GlobPatternHelper.ResolveDestinationPath(destination, fileName);\n+\n+            // Assert\n+            result.Should().Be(\"C:/downloads/myfile.txt\");\n+        }\n+\n+        [TestMethod]\n+        public void ResolveDestinationPath_DestinationEndsWithBackslash_AppendsFilename()\n+        {\n+            // Arrange\n+            var destination = @\"C:\\downloads\\\";\n+            var fileName = \"data.json\";\n+\n+            // Act\n+            var result = GlobPatternHelper.ResolveDestinationPath(destination, fileName);\n+\n+            // Assert\n+            result.Should().Be(@\"C:\\downloads/data.json\");\n+        }\n+\n+        [TestMethod]\n+        public void ResolveDestinationPath_DestinationIsFilename_ReturnsAsIs()\n+        {\n+            // Arrange\n+            var destination = @\"C:\\downloads\\renamed.txt\";\n+            var fileName = \"original.txt\";\n+\n+            // Act\n+            var result = GlobPatternHelper.ResolveDestinationPath(destination, fileName);\n+\n+            // Assert\n+            result.Should().Be(@\"C:\\downloads\\renamed.txt\");\n+        }\n+\n+        [TestMethod]\n+        public void ResolveDestinationPath_RelativeDirectory_AppendsFilename()\n+        {\n+            // Arrange\n+            var destination = \"./output/\";\n+            var fileName = \"report.csv\";\n+\n+            // Act\n+            var result = GlobPatternHelper.ResolveDestinationPath(destination, fileName);\n+\n+            // Assert\n+            result.Should().Be(\"./output/report.csv\");\n+        }\n+\n+        #endregion\n+\n+        #region ReconstructFullPath Tests\n+\n+        [TestMethod]\n+        public void ReconstructFullPath_WithBaseDir_PrependsDirectory()\n+        {\n+            // Arrange\n+            var baseDir = \"logs\";\n+            var relativePath = \"app.log\";\n+\n+            // Act\n+            var result = GlobPatternHelper.ReconstructFullPath(baseDir, relativePath);\n+\n+            // Assert\n+            result.Should().Be(\"logs/app.log\");\n+        }\n+\n+        [TestMethod]\n+        public void ReconstructFullPath_EmptyBaseDir_ReturnsRelativePath()\n+        {\n+            // Arrange\n+            var baseDir = \"\";\n+            var relativePath = \"file.txt\";\n+\n+            // Act\n+            var result = GlobPatternHelper.ReconstructFullPath(baseDir, relativePath);\n+\n+            // Assert\n+            result.Should().Be(\"file.txt\");\n+        }\n+\n+        [TestMethod]\n+        public void ReconstructFullPath_DotBaseDir_ReturnsRelativePath()\n+        {\n+            // Arrange\n+            var baseDir = \".\";\n+            var relativePath = \"config.json\";\n+\n+            // Act\n+            var result = GlobPatternHelper.ReconstructFullPath(baseDir, relativePath);\n+\n+            // Assert\n+            result.Should().Be(\"config.json\");\n+        }\n+\n+        [TestMethod]\n+        public void ReconstructFullPath_NormalizesBackslashes()\n+        {\n+            // Arrange\n+            var baseDir = @\"data\\files\";\n+            var relativePath = \"output.csv\";\n+\n+            // Act\n+            var result = GlobPatternHelper.ReconstructFullPath(baseDir, relativePath);\n+\n+            // Assert\n+            result.Should().Be(\"data/files/output.csv\");\n+        }\n+\n+        [TestMethod]\n+        public void ReconstructFullPath_TrimsTrailingSlash()\n+        {\n+            // Arrange\n+            var baseDir = \"logs/\";\n+            var relativePath = \"error.log\";\n+\n+            // Act\n+            var result = GlobPatternHelper.ReconstructFullPath(baseDir, relativePath);\n+\n+            // Assert\n+            result.Should().Be(\"logs/error.log\");\n+        }\n+\n+        [TestMethod]\n+        public void ReconstructFullPath_TrimsLeadingSlashFromRelative()\n+        {\n+            // Arrange\n+            var baseDir = \"data\";\n+            var relativePath = \"/file.txt\";\n+\n+            // Act\n+            var result = GlobPatternHelper.ReconstructFullPath(baseDir, relativePath);\n+\n+            // Assert\n+            result.Should().Be(\"data/file.txt\");\n+        }\n+\n+        #endregion\n+\n+        #region ApplyQuestionMarkFilter Tests\n+\n+        [TestMethod]\n+        public void ApplyQuestionMarkFilter_NoQuestionMark_ReturnsAllFiles()\n+        {\n+            // Arrange\n+            var files = new[] { \"file1.txt\", \"file2.txt\", \"data.log\" };\n+            var pattern = \"*.txt\";\n+\n+            // Act\n+            var result = GlobPatternHelper.ApplyQuestionMarkFilter(files, pattern, f => f).ToList();\n+\n+            // Assert\n+            result.Should().HaveCount(3, \"no ? in pattern, all files should pass through\");\n+        }\n+\n+        [TestMethod]\n+        public void ApplyQuestionMarkFilter_WithQuestionMark_FiltersSingleChar()\n+        {\n+            // Arrange\n+            var files = new[] { \"file1.txt\", \"file2.txt\", \"file12.txt\", \"file.txt\" };\n+            var pattern = \"file?.txt\";\n+\n+            // Act\n+            var result = GlobPatternHelper.ApplyQuestionMarkFilter(files, pattern, f => f).ToList();\n+\n+            // Assert\n+            result.Should().HaveCount(2);\n+            result.Should().Contain(\"file1.txt\");\n+            result.Should().Contain(\"file2.txt\");\n+            result.Should().NotContain(\"file12.txt\", \"12 is two chars, not one\");\n+            result.Should().NotContain(\"file.txt\", \"missing the required single char\");\n+        }\n+\n+        [TestMethod]\n+        public void ApplyQuestionMarkFilter_MultipleQuestionMarks_FiltersCorrectly()\n+        {\n+            // Arrange\n+            var files = new[] { \"log01.txt\", \"log12.txt\", \"log1.txt\", \"log123.txt\" };\n+            var pattern = \"log??.txt\";\n+\n+            // Act\n+            var result = GlobPatternHelper.ApplyQuestionMarkFilter(files, pattern, f => f).ToList();\n+\n+            // Assert\n+            result.Should().HaveCount(2);\n+            result.Should().Contain(\"log01.txt\");\n+            result.Should().Contain(\"log12.txt\");\n+        }\n+\n+        [TestMethod]\n+        public void ApplyQuestionMarkFilter_CaseInsensitive()\n+        {\n+            // Arrange\n+            var files = new[] { \"FILE1.TXT\", \"file2.txt\", \"File3.Txt\" };\n+            var pattern = \"file?.txt\";\n+\n+            // Act\n+            var result = GlobPatternHelper.ApplyQuestionMarkFilter(files, pattern, f => f).ToList();\n+\n+            // Assert\n+            result.Should().HaveCount(3, \"matching should be case-insensitive\");\n+        }\n+\n+        [TestMethod]\n+        public void ApplyQuestionMarkFilter_WithCustomGetFileName()\n+        {\n+            // Arrange - simulating FileInfoEntry-like objects\n+            var files = new[]\n+            {\n+                new { Path = \"/logs/file1.log\", Size = 100 },\n+                new { Path = \"/logs/file12.log\", Size = 200 },\n+                new { Path = \"/logs/file2.log\", Size = 300 }\n+            };\n+            var pattern = \"file?.log\";\n+\n+            // Act\n+            var result = GlobPatternHelper.ApplyQuestionMarkFilter(\n+                files, \n+                pattern, \n+                f => System.IO.Path.GetFileName(f.Path)).ToList();\n+\n+            // Assert\n+            result.Should().HaveCount(2);\n+            result.Select(f => f.Path).Should().Contain(\"/logs/file1.log\");\n+            result.Select(f => f.Path).Should().Contain(\"/logs/file2.log\");\n+        }\n+\n+        #endregion\n     }\n }\ndiff --git a/BitPantry.CommandLine.Tests.Remote.SignalR/ClientTests/UploadCommandTests.cs b/BitPantry.CommandLine.Tests.Remote.SignalR/ClientTests/UploadCommandTests.cs\nindex 505cfa3..35abafc 100644\n--- a/BitPantry.CommandLine.Tests.Remote.SignalR/ClientTests/UploadCommandTests.cs\n+++ b/BitPantry.CommandLine.Tests.Remote.SignalR/ClientTests/UploadCommandTests.cs\n@@ -4,6 +4,7 @@ using BitPantry.CommandLine.Component;\n using BitPantry.CommandLine.Processing.Execution;\n using BitPantry.CommandLine.Remote.SignalR.Client;\n using BitPantry.CommandLine.Remote.SignalR.Client.Commands.Server;\n+using BitPantry.CommandLine.Tests.Remote.SignalR.Helpers;\n using FluentAssertions;\n using Moq;\n using Spectre.Console;\n@@ -27,16 +28,9 @@ namespace BitPantry.CommandLine.Tests.Remote.SignalR.ClientTests\n         [TestInitialize]\n         public void Setup()\n         {\n-            _proxyMock = new Mock<IServerProxy>();\n+            _proxyMock = TestServerProxyFactory.CreateConnected();\n             _console = new TestConsole();\n             _fileSystem = new MockFileSystem();\n-            \n-            _proxyMock.Setup(p => p.ConnectionState).Returns(ServerProxyConnectionState.Connected);\n-            _proxyMock.Setup(p => p.Server).Returns(new ServerCapabilities(\n-                new Uri(\"https://localhost:5000\"),\n-                \"test-connection-id\",\n-                new List<CommandInfo>(),\n-                100 * 1024 * 1024)); // 100MB default\n         }\n \n         #region Connection Verification Tests (CV-009, CV-010, CV-011, UX-007, EH-001)\ndiff --git a/CLAUDE.md b/CLAUDE.md\nindex 3febb76..bb27238 100644\n--- a/CLAUDE.md\n+++ b/CLAUDE.md\n@@ -114,6 +114,41 @@ console.Should().HaveLineContaining(row: 5, \"Progress:\");\n - **\"Then: displays X\"** ΓåÆ UX test with VirtualConsoleAssertions\n - **\"Then: file appears on server\"** ΓåÆ Integration test with real temp filesystem\n \n+### Shared Test Helpers (`Helpers/`)\n+\n+Reusable test infrastructure in `BitPantry.CommandLine.Tests.Remote.SignalR/Helpers/`:\n+\n+| Helper | Purpose | Usage |\n+|--------|---------|-------|\n+| `TestServerProxyFactory` | Creates `Mock<IServerProxy>` with standard ServerCapabilities | `TestServerProxyFactory.CreateConnected()`, `.CreateDisconnected()` |\n+| `TestFileTransferServiceFactory` | Creates `FileTransferService` with all mocks wired up | `.Create(proxyMock)`, `.CreateWithContext(proxyMock)` |\n+| `FileTransferServiceTestContext` | Exposes all mocks from factory for test verification | `_context.Service`, `_context.HttpMessageHandlerMock`, `_context.SetupAuthenticatedTokenAsync()` |\n+| `TempFileScope` | Disposable temp file with automatic cleanup | `using var tempFile = new TempFileScope(\"content\");` |\n+| `TestAccessTokenManager` | Creates AccessTokenManager with mocked HTTP | `TestAccessTokenManager.Create(httpResponse)` |\n+| `TestJwtTokenService` | Generates valid test JWT tokens | `TestJwtTokenService.GenerateAccessToken()` |\n+| `TestHttpClient` | Pre-configured HttpClient for tests | Various HTTP testing scenarios |\n+\n+**Usage Example:**\n+```csharp\n+[TestInitialize]\n+public void Setup()\n+{\n+    _proxyMock = TestServerProxyFactory.CreateConnected();\n+    _context = TestFileTransferServiceFactory.CreateWithContext(_proxyMock);\n+}\n+\n+[TestMethod]\n+public async Task Download_ValidFile_Succeeds()\n+{\n+    await _context.SetupAuthenticatedTokenAsync();\n+    using var tempFile = new TempFileScope();\n+    \n+    await _context.Service.DownloadFile(\"file.txt\", tempFile.Path, CancellationToken.None);\n+    \n+    tempFile.ReadAllText().Should().Contain(\"expected content\");\n+}\n+```\n+\n ### Bug Fix Process (Quick Reference)\n \n When fixing bugs, follow this structured approach:"
  }
}
